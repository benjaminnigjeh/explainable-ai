{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dae5ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: F:\\binary\\assignments_with_quant_sums_aaa.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------\n",
    "# Config (edit paths)\n",
    "# --------------------\n",
    "DATASET_RT_PATH = r\"F:\\binary\\neuro_training.csv\"   # wide matrix; columns \"0\",\"1\",... plus 'bin','target'\n",
    "ASSIGNMENTS_PATH = r\"F:\\binary\\ids.csv\"   # has 'bin' and 'matched_mz_list'\n",
    "OUT_PATH = os.path.join(os.path.dirname(ASSIGNMENTS_PATH) or \".\", \"assignments_with_quant_sums_aaa.csv\")\n",
    "\n",
    "# m/z -> column index mapping (make sure this matches how your matrix was created)\n",
    "MZ_BASE = 600.0     # m/z at column 0\n",
    "MZ_STEP = 0.1       # bin width in m/z\n",
    "USE_NEAREST = True  # True: round to nearest bin; False: truncate toward zero\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "def to_col_index(mz: float) -> int:\n",
    "    \"\"\"Map m/z to integer feature index according to BASE/STEP.\"\"\"\n",
    "    x = (float(mz) - MZ_BASE) / MZ_STEP\n",
    "    return int(round(x)) if USE_NEAREST else int(x)\n",
    "\n",
    "def parse_mz_list(val):\n",
    "    \"\"\"Safely parse matched_mz_list cells like '[864.9, 865.2, ...]'. Returns [] on failure.\"\"\"\n",
    "    try:\n",
    "        out = ast.literal_eval(str(val))\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            return [float(x) for x in out]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "def snap_bins(series: pd.Series, valid_bins: np.ndarray) -> pd.Series:\n",
    "    \"\"\"Snap each numeric value in `series` to the nearest value in `valid_bins`.\"\"\"\n",
    "    arr = pd.to_numeric(series, errors=\"coerce\").astype(float).to_numpy()\n",
    "    snapped = []\n",
    "    for v in arr:\n",
    "        if np.isnan(v):\n",
    "            snapped.append(np.nan)\n",
    "        else:\n",
    "            idx = int(np.argmin(np.abs(valid_bins - v)))\n",
    "            snapped.append(float(valid_bins[idx]))\n",
    "    return pd.Series(snapped, index=series.index, dtype=float)\n",
    "\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "df_rt = pd.read_csv(DATASET_RT_PATH)\n",
    "df_asn = pd.read_csv(ASSIGNMENTS_PATH)\n",
    "\n",
    "# Basic checks\n",
    "for col in [\"bin\", \"target\"]:\n",
    "    if col not in df_rt.columns:\n",
    "        raise KeyError(f\"'{col}' column is required in the dataset CSV: {DATASET_RT_PATH}\")\n",
    "\n",
    "if \"bin\" not in df_asn.columns or \"matched_mz_list\" not in df_asn.columns:\n",
    "    raise KeyError(\"Assignments CSV must contain 'bin' and 'matched_mz_list' columns\")\n",
    "\n",
    "# Normalize dataset bins\n",
    "rt_bins_unique = np.array(sorted(pd.to_numeric(df_rt[\"bin\"], errors=\"coerce\").dropna().unique()), dtype=float)\n",
    "if rt_bins_unique.size == 0:\n",
    "    raise ValueError(\"No valid numeric bins found in the dataset.\")\n",
    "\n",
    "# Snap both sides to nearest dataset bin to avoid float equality issues\n",
    "df_rt[\"__bin_norm__\"] = pd.to_numeric(df_rt[\"bin\"], errors=\"coerce\").astype(float)\n",
    "df_asn[\"__bin_norm__\"] = snap_bins(df_asn[\"bin\"], rt_bins_unique)\n",
    "\n",
    "# Prepare feature column label handling (string labels like \"0\",\"1\",...)\n",
    "RESERVED = {\"bin\", \"target\", \"__bin_norm__\"}\n",
    "feat_cols_all = [c for c in df_rt.columns if c not in RESERVED]\n",
    "feat_str_set = set(map(str, feat_cols_all))  # treat all labels as strings for selection\n",
    "\n",
    "# --------------------\n",
    "# Prepare output columns\n",
    "# --------------------\n",
    "new_cols = [\"group_0_sum\", \"group_1_sum\", \"n_mz_used\", \"n_mz_found\", \"missing_cast_columns\"]\n",
    "for c in new_cols:\n",
    "    if c in df_asn.columns:\n",
    "        df_asn.drop(columns=[c], inplace=True)\n",
    "\n",
    "# --------------------\n",
    "# Row-wise quantification\n",
    "# --------------------\n",
    "results = []\n",
    "for _, row in df_asn.iterrows():\n",
    "    bin_value = row[\"__bin_norm__\"]\n",
    "    mz_list = parse_mz_list(row[\"matched_mz_list\"])\n",
    "    idxs = [to_col_index(mz) for mz in mz_list]\n",
    "    req_labels = [str(i) for i in idxs]  # match df_rt's string column labels\n",
    "\n",
    "    # Slice dataset rows at this snapped bin\n",
    "    df_bin = df_rt[df_rt[\"__bin_norm__\"] == bin_value]\n",
    "    if df_bin.empty:\n",
    "        # Should be rare thanks to snapping; still handle\n",
    "        results.append(dict(\n",
    "            group_0_sum=float(\"nan\"),\n",
    "            group_1_sum=float(\"nan\"),\n",
    "            n_mz_used=len(req_labels),\n",
    "            n_mz_found=0,\n",
    "            missing_cast_columns=\", \".join(req_labels) if req_labels else \"\"\n",
    "        ))\n",
    "        continue\n",
    "\n",
    "    # Which requested features exist in this dataset?\n",
    "    existing = [c for c in req_labels if c in df_bin.columns]\n",
    "    missing = [c for c in req_labels if c not in df_bin.columns]\n",
    "\n",
    "    if not existing:\n",
    "        sums = {0: float(\"nan\"), 1: float(\"nan\")}\n",
    "        n_found = 0\n",
    "    else:\n",
    "        # Sum across the selected feature columns per target (two groups: 0 and 1)\n",
    "        grouped = df_bin.groupby(\"target\")[existing].sum()\n",
    "        total_per_target = grouped.sum(axis=1)  # collapse across the requested columns\n",
    "        sums = {t: float(total_per_target.get(t, float(\"nan\"))) for t in [0, 1]}\n",
    "        n_found = len(existing)\n",
    "\n",
    "    results.append(dict(\n",
    "        group_0_sum=sums[0],\n",
    "        group_1_sum=sums[1],\n",
    "        n_mz_used=len(req_labels),\n",
    "        n_mz_found=n_found,\n",
    "        missing_cast_columns=\", \".join(missing)\n",
    "    ))\n",
    "\n",
    "# Attach results and save\n",
    "df_quant = pd.DataFrame(results, index=df_asn.index)\n",
    "df_out = pd.concat([df_asn, df_quant], axis=1)\n",
    "df_out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Saved: {OUT_PATH}\")\n",
    "\n",
    "# --------------------\n",
    "# Tips:\n",
    "# - If you discover your matrix used a different BASE/STEP,\n",
    "#   update MZ_BASE / MZ_STEP above.\n",
    "# - If your assignments' bins are exactly {5, 15} already,\n",
    "#   you could skip snapping and compare directly.\n",
    "# --------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
