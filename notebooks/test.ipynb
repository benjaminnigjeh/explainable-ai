{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e48b700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benja\\AppData\\Local\\Temp\\ipykernel_8552\\4011789488.py:318: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  df2[\"PFR\"] = pd.to_numeric(df2[\"PFR\"], errors=\"ignore\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved with 1 sets of columns (best_match / matched_pfr / mode_pfr / mode_pfr_count / mode_accession) → F:/idbenchmark/assignments_with_quant_sums_pfr.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Combine charge-assignment summary with best matches from a databank,\n",
    "supporting MULTIPLE (rt_window, mz_tol, mass_tol) triplets in one run.\n",
    "\n",
    "- Reads:\n",
    "    df1: assignments_summary (must have: neutral_mass, bin (or 'bin '), matched_mz_list)\n",
    "    df2: databank_with_ids (must have: rt_aligned, precursor_mz, MASS, Accession, PFR)\n",
    "\n",
    "- For each row in df1, for each m/z in matched_mz_list:\n",
    "    find the single best df2 row where ALL hold:\n",
    "        |rt_aligned - bin|    <= rt_window\n",
    "        |precursor_mz - m/z|  <= mz_tol\n",
    "        |MASS - neutral_mass| <= mass_tol\n",
    "  Then format:\n",
    "      best_match_* : \"[<mz>: <Accession>, <MASS_from_df2>, <PFR>] ...\"  (PFR optional)\n",
    "      matched_pfr_*: \"[<PFR_or_null_per_mz> ...]\"  (aligned with matched_mz_list)\n",
    "      mode_pfr_*   : most common non-null PFR across matches (per row)\n",
    "      mode_pfr_count_* : frequency (count) of that PFR (non-null only)\n",
    "      mode_accession_* : most common Accession across matches (per row), shown only if mode_pfr_count_* >= MIN_MODE_PFR_COUNT\n",
    "\n",
    "- Outputs:\n",
    "    One CSV with multiple columns per tolerance triplet:\n",
    "      best_match_rt<RT>_mz<MZ>_mass<MASS>\n",
    "      matched_pfr_rt<RT>_mz<MZ>_mass<MASS>\n",
    "      mode_pfr_rt<RT>_mz<MZ>_mass<MASS>\n",
    "      mode_pfr_count_rt<RT>_mz<MZ>_mass<MASS>\n",
    "      mode_accession_rt<RT>_mz<MZ>_mass<MASS>\n",
    "\n",
    "Edit the 3 PATHS and the PARAM_SETS below before running.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import ast\n",
    "from typing import Optional, Dict, List, Tuple, Any\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG: edit these paths\n",
    "# ----------------------------\n",
    "CHARGE_FILE_PATH = r\"F:/idbenchmark/assignments_with_quant_sums.csv\"\n",
    "DATABANK_PATH    = r\"F:/idbenchmark/databank_pfr_clean.csv\"\n",
    "OUTPUT_PATH      = r\"F:/idbenchmark/assignments_with_quant_sums_pfr.csv\"\n",
    "\n",
    "# Provide one or more (rt_window, mz_tol, mass_tol) triplets here.\n",
    "PARAM_SETS: List[Tuple[float, float, float]] = [\n",
    "    (55.0, 2.0, 90.0),\n",
    "    # (30.0, 1.0, 50.0),\n",
    "]\n",
    "\n",
    "# Keep \"null\" placeholders in matched_pfr_* so positions align with mz_list.\n",
    "PFR_KEEP_PLACEHOLDERS: bool = True\n",
    "\n",
    "# Minimum frequency required to report mode PFR and mode Accession.\n",
    "MIN_MODE_PFR_COUNT: int = 1\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def _num(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Coerce to numeric, invalid → NaN.\"\"\"\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def _to_scalar(x: Any) -> Any:\n",
    "    \"\"\"Flatten 0-d arrays and coerce numeric strings to float when possible.\"\"\"\n",
    "    if isinstance(x, np.ndarray) and x.ndim == 0:\n",
    "        x = x.item()\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return x\n",
    "    return x\n",
    "\n",
    "\n",
    "def _safe_parse_list(val) -> List[float]:\n",
    "    \"\"\"Convert a string-repr list into a Python list of floats safely.\"\"\"\n",
    "    if isinstance(val, str):\n",
    "        try:\n",
    "            parsed = ast.literal_eval(val)\n",
    "            if isinstance(parsed, (list, tuple, np.ndarray)):\n",
    "                return [float(x) for x in parsed]\n",
    "            return []\n",
    "        except Exception:\n",
    "            return []\n",
    "    if isinstance(val, (list, tuple, np.ndarray)):\n",
    "        try:\n",
    "            return [float(x) for x in val]\n",
    "        except Exception:\n",
    "            return []\n",
    "    return []\n",
    "\n",
    "\n",
    "def _ensure_columns(df: pd.DataFrame, required: List[str]) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing required column(s): {missing}\")\n",
    "\n",
    "\n",
    "def _fmt_suffix(v: float) -> str:\n",
    "    \"\"\"\n",
    "    Make a tidy string for column suffixes (avoid many decimals).\n",
    "    e.g., 10 -> '10', 2.0 -> '2', 1.5 -> '1p5'\n",
    "    \"\"\"\n",
    "    if float(v).is_integer():\n",
    "        return f\"{int(v)}\"\n",
    "    # Replace '.' with 'p' to keep it column-name friendly\n",
    "    return str(v).replace('.', 'p')\n",
    "\n",
    "\n",
    "def _mode_or_none(items: List[Any]) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Return the most common value in `items` excluding None/NaN.\n",
    "    If tie, Counter.most_common returns first encountered top count.\n",
    "    \"\"\"\n",
    "    clean = []\n",
    "    for v in items:\n",
    "        if v is None:\n",
    "            continue\n",
    "        if isinstance(v, float) and np.isnan(v):\n",
    "            continue\n",
    "        clean.append(v)\n",
    "    if not clean:\n",
    "        return None\n",
    "    return Counter(clean).most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def _mode_and_count(items: List[Any]) -> Tuple[Optional[Any], int]:\n",
    "    \"\"\"\n",
    "    Return (mode_value, count) over non-null items.\n",
    "    If no non-null items, returns (None, 0).\n",
    "    \"\"\"\n",
    "    clean = []\n",
    "    for v in items:\n",
    "        if v is None:\n",
    "            continue\n",
    "        if isinstance(v, float) and np.isnan(v):\n",
    "            continue\n",
    "        clean.append(v)\n",
    "    if not clean:\n",
    "        return None, 0\n",
    "    val, cnt = Counter(clean).most_common(1)[0]\n",
    "    return val, int(cnt)\n",
    "\n",
    "\n",
    "def _mode_and_count_with_cutoff(\n",
    "    pfrs: List[Any], accs: List[Any], min_count: int\n",
    ") -> Tuple[Optional[Any], int, Optional[Any]]:\n",
    "    \"\"\"\n",
    "    Return (mode_pfr, count, mode_accession) applying a frequency cutoff on PFR.\n",
    "    If the mode PFR count < min_count, return (None, 0, None).\n",
    "    Otherwise return (mode_pfr, count, mode_accession).\n",
    "    \"\"\"\n",
    "    pfr_val, pfr_cnt = _mode_and_count(pfrs)\n",
    "    acc_val = _mode_or_none(accs)\n",
    "\n",
    "    if pfr_cnt < min_count:\n",
    "        return None, 0, None\n",
    "    return pfr_val, pfr_cnt, acc_val\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Core search\n",
    "# ----------------------------\n",
    "def search_best(\n",
    "    df2: pd.DataFrame,\n",
    "    rt_query: float,\n",
    "    mz_query: float,\n",
    "    mass_query: float,\n",
    "    rt_window: float,\n",
    "    mz_tol: float,\n",
    "    mass_tol: float\n",
    ") -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Return the single best match (row as dict) if ALL three criteria match:\n",
    "      |rt - rt_query| <= rt_window\n",
    "      |mz - mz_query| <= mz_tol\n",
    "      |mass - mass_query| <= mass_tol\n",
    "    Otherwise returns None.\n",
    "    \"\"\"\n",
    "    d_rt   = (df2[\"rt_aligned\"] - float(rt_query)).abs()\n",
    "    d_mz   = (df2[\"precursor_mz\"] - float(mz_query)).abs()\n",
    "    d_mass = (df2[\"MASS\"] - float(mass_query)).abs()\n",
    "\n",
    "    mask = (d_rt <= rt_window) & (d_mz <= mz_tol) & (d_mass <= mass_tol)\n",
    "    if not mask.any():\n",
    "        return None\n",
    "\n",
    "    cand = df2.loc[mask].copy()\n",
    "    cand[\"score\"] = (\n",
    "        d_rt.loc[cand.index] / max(rt_window, 1e-12) +\n",
    "        d_mz.loc[cand.index] / max(mz_tol, 1e-12) +\n",
    "        d_mass.loc[cand.index] / max(mass_tol, 1e-12)\n",
    "    )\n",
    "    best_row = cand.sort_values(\"score\", kind=\"mergesort\").iloc[0]\n",
    "    return best_row.to_dict()\n",
    "\n",
    "\n",
    "# ---------- per-row collectors (single pass across m/z list) ----------\n",
    "def _collect_matches_for_row(\n",
    "    row: pd.Series,\n",
    "    df2: pd.DataFrame,\n",
    "    rt_window: float,\n",
    "    mz_tol: float,\n",
    "    mass_tol: float\n",
    ") -> Tuple[List[str], List[Optional[Any]], List[Optional[str]], List[Optional[float]]]:\n",
    "    \"\"\"\n",
    "    For a df1 row, iterate over matched_mz_list and collect:\n",
    "      - mz_tokens for best_match string (aligned, with placeholders)\n",
    "      - pfr_list  (aligned, None for missing/NaN)\n",
    "      - acc_list  (aligned, None for no match)\n",
    "      - mass_list (aligned, MASS from df2 if matched, else None)\n",
    "\n",
    "    Returns (best_match_tokens, pfr_list, acc_list, mass_list).\n",
    "    \"\"\"\n",
    "    neutral_mass   = row.get(\"neutral_mass\", np.nan)\n",
    "    retention_time = row.get(\"bin\", row.get(\"bin \", np.nan))\n",
    "    mz_list        = _safe_parse_list(row.get(\"matched_mz_list\", []))\n",
    "\n",
    "    if pd.isna(neutral_mass) or pd.isna(retention_time) or not mz_list:\n",
    "        return [], [], [], []\n",
    "\n",
    "    tokens: List[str] = []\n",
    "    pfrs:   List[Optional[Any]]   = []\n",
    "    accs:   List[Optional[str]]   = []\n",
    "    masses: List[Optional[float]] = []\n",
    "\n",
    "    for mz_value in mz_list:\n",
    "        res = search_best(\n",
    "            df2,\n",
    "            rt_query=float(retention_time),\n",
    "            mz_query=float(mz_value),\n",
    "            mass_query=float(neutral_mass),\n",
    "            rt_window=rt_window,\n",
    "            mz_tol=mz_tol,\n",
    "            mass_tol=mass_tol,\n",
    "        )\n",
    "        if res is not None:\n",
    "            uniprot_id = res.get(\"Accession\", \"NA\")\n",
    "            mass_match = _to_scalar(res.get(\"MASS\", neutral_mass))\n",
    "            pfr_val    = _to_scalar(res.get(\"PFR\", None))\n",
    "            if pfr_val is None or (isinstance(pfr_val, float) and np.isnan(pfr_val)):\n",
    "                tokens.append(f\"{mz_value}: {uniprot_id}, {mass_match}\")\n",
    "                pfrs.append(None)\n",
    "            else:\n",
    "                tokens.append(f\"{mz_value}: {uniprot_id}, {mass_match}, {pfr_val}\")\n",
    "                pfrs.append(pfr_val)\n",
    "            accs.append(uniprot_id)\n",
    "            masses.append(mass_match)\n",
    "        else:\n",
    "            tokens.append(f\"{mz_value}: NA\")\n",
    "            pfrs.append(None)\n",
    "            accs.append(None)\n",
    "            masses.append(None)\n",
    "\n",
    "    return tokens, pfrs, accs, masses\n",
    "\n",
    "\n",
    "def best_match_formatter_from_tokens(tokens: List[str]) -> Optional[str]:\n",
    "    if not tokens:\n",
    "        return None\n",
    "    return \"[\" + \", \".join(tokens) + \"]\"\n",
    "\n",
    "\n",
    "def matched_pfr_from_list(pfrs: List[Optional[Any]], keep_placeholders: bool) -> Optional[str]:\n",
    "    if not pfrs:\n",
    "        return None\n",
    "    if keep_placeholders:\n",
    "        return \"[\" + \", \".join(\"null\" if v is None else str(v) for v in pfrs) + \"]\"\n",
    "    else:\n",
    "        pruned = [str(v) for v in pfrs if v is not None]\n",
    "        return \"[\" + \", \".join(pruned) + \"]\" if pruned else None\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Main\n",
    "# ----------------------------\n",
    "def main():\n",
    "    # Load CSVs\n",
    "    if not os.path.exists(CHARGE_FILE_PATH):\n",
    "        raise FileNotFoundError(f\"Not found: {CHARGE_FILE_PATH}\")\n",
    "    if not os.path.exists(DATABANK_PATH):\n",
    "        raise FileNotFoundError(f\"Not found: {DATABANK_PATH}\")\n",
    "\n",
    "    df1 = pd.read_csv(CHARGE_FILE_PATH)\n",
    "    df2 = pd.read_csv(DATABANK_PATH)\n",
    "\n",
    "    # Normalize df1 column names to handle accidental trailing spaces, capitalization, etc.\n",
    "    df1.columns = [c.strip() for c in df1.columns]\n",
    "\n",
    "    # Ensure required columns in both tables (with tolerant check for 'bin' / 'bin ')\n",
    "    need_df1 = [\"neutral_mass\", \"matched_mz_list\"]\n",
    "    _ensure_columns(df1, need_df1)\n",
    "    if \"bin\" not in df1.columns and \"bin \" not in df1.columns:\n",
    "        raise KeyError(\"df1 must contain 'bin' (or 'bin ').\")\n",
    "\n",
    "    # Ensure essential df2 columns (PFR required for the new output)\n",
    "    _ensure_columns(df2, [\"rt_aligned\", \"precursor_mz\", \"MASS\", \"Accession\", \"PFR\"])\n",
    "\n",
    "    # If df1 had 'bin ' originally, create 'bin' as an alias to simplify downstream code\n",
    "    if \"bin\" not in df1.columns and \"bin \" in df1.columns:\n",
    "        df1[\"bin\"] = df1[\"bin \"]\n",
    "\n",
    "    # Pre-coerce df2 numerics once (for speed)\n",
    "    df2 = df2.copy()\n",
    "    df2[\"rt_aligned\"]   = _num(df2[\"rt_aligned\"])\n",
    "    df2[\"precursor_mz\"] = _num(df2[\"precursor_mz\"])\n",
    "    df2[\"MASS\"]         = _num(df2[\"MASS\"])\n",
    "    # PFR can be numeric or categorical; try to coerce but keep strings if not\n",
    "    try:\n",
    "        df2[\"PFR\"] = pd.to_numeric(df2[\"PFR\"], errors=\"ignore\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Build output columns per tolerance triplet\n",
    "    for (rt_w, mz_t, mass_t) in PARAM_SETS:\n",
    "        suffix = f\"rt{_fmt_suffix(rt_w)}_mz{_fmt_suffix(mz_t)}_mass{_fmt_suffix(mass_t)}\"\n",
    "\n",
    "        match_col   = f\"best_match_{suffix}\"\n",
    "        pfr_col     = f\"matched_pfr_{suffix}\"\n",
    "        mode_pfr    = f\"mode_pfr_{suffix}\"\n",
    "        mode_pfr_n  = f\"mode_pfr_count_{suffix}\"\n",
    "        mode_acc    = f\"mode_accession_{suffix}\"\n",
    "\n",
    "        best_tokens_series: List[List[str]] = []\n",
    "        pfr_list_series:    List[List[Optional[Any]]] = []\n",
    "        acc_list_series:    List[List[Optional[str]]] = []\n",
    "\n",
    "        # Compute per-row tokens and lists in one pass\n",
    "        for _, row in df1.iterrows():\n",
    "            tokens, pfrs, accs, _masses = _collect_matches_for_row(\n",
    "                row, df2, rt_window=rt_w, mz_tol=mz_t, mass_tol=mass_t\n",
    "            )\n",
    "            best_tokens_series.append(tokens)\n",
    "            pfr_list_series.append(pfrs)\n",
    "            acc_list_series.append(accs)\n",
    "\n",
    "        # Populate columns\n",
    "        df1[match_col] = [best_match_formatter_from_tokens(toks) for toks in best_tokens_series]\n",
    "        df1[pfr_col]   = [matched_pfr_from_list(pfrs, keep_placeholders=PFR_KEEP_PLACEHOLDERS)\n",
    "                          for pfrs in pfr_list_series]\n",
    "\n",
    "        # Most common PFR + its frequency (with cutoff), and most common Accession (masked if cutoff not met)\n",
    "        mode_results = [\n",
    "            _mode_and_count_with_cutoff(pfrs, accs, min_count=MIN_MODE_PFR_COUNT)\n",
    "            for pfrs, accs in zip(pfr_list_series, acc_list_series)\n",
    "        ]\n",
    "        df1[mode_pfr]   = [mr[0] for mr in mode_results]\n",
    "        df1[mode_pfr_n] = [mr[1] for mr in mode_results]\n",
    "        df1[mode_acc]   = [mr[2] for mr in mode_results]\n",
    "\n",
    "    # Save single CSV containing all columns\n",
    "    out_dir = os.path.dirname(OUTPUT_PATH) or \".\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    df1.to_csv(OUTPUT_PATH, index=False)\n",
    "    print(\n",
    "        f\"Saved with {len(PARAM_SETS)} sets of columns \"\n",
    "        f\"(best_match / matched_pfr / mode_pfr / mode_pfr_count / mode_accession) → {OUTPUT_PATH}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
