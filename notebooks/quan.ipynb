{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cb998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: F:\\test\\assignments_with_quant_sums.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# --------------------\n",
    "# Config (edit paths)\n",
    "# --------------------\n",
    "DATASET_RT_PATH = r\"F:\\casts\\databank\\csv_files\\dataset_rt.csv\"          # wide matrix with cast_* columns\n",
    "ASSIGNMENTS_PATH = r\"F:\\test\\assignments_with_best_matches.csv\"          # has 'bin' and 'matched_mz_list'\n",
    "OUT_PATH = os.path.join(\n",
    "    os.path.dirname(ASSIGNMENTS_PATH) or \".\",\n",
    "    \"assignments_with_quant_sums.csv\"\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Helpers\n",
    "# --------------------\n",
    "def to_cast_col(n: float) -> str:\n",
    "    \"\"\"Map an m/z to its cast_* column name: int((mz-600)*10), zero-padded.\"\"\"\n",
    "    col_num = int((float(n) - 600.0) * 10.0)\n",
    "    return \"cast_\" + str(col_num).zfill(5)\n",
    "\n",
    "def parse_mz_list(val):\n",
    "    \"\"\"Safely parse matched_mz_list cells that look like '[864.9, 865.2, ...]'.\"\"\"\n",
    "    try:\n",
    "        out = ast.literal_eval(str(val))\n",
    "        if isinstance(out, (list, tuple)):\n",
    "            return [float(x) for x in out]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return []\n",
    "\n",
    "# --------------------\n",
    "# Load data\n",
    "# --------------------\n",
    "df_rt = pd.read_csv(DATASET_RT_PATH)\n",
    "df_asn = pd.read_csv(ASSIGNMENTS_PATH)\n",
    "\n",
    "# Basic checks\n",
    "for col in [\"bin\", \"target\"]:\n",
    "    if col not in df_rt.columns:\n",
    "        raise KeyError(f\"'{col}' column is required in dataset_rt.csv\")\n",
    "\n",
    "if \"bin\" not in df_asn.columns or \"matched_mz_list\" not in df_asn.columns:\n",
    "    raise KeyError(\"assignments CSV must contain 'bin' and 'matched_mz_list' columns\")\n",
    "\n",
    "# NEW columns to be added to assignments\n",
    "new_cols = [\"group_0_sum\", \"group_1_sum\", \"group_2_sum\", \"group_3_sum\",\n",
    "            \"n_mz_used\", \"n_mz_found\", \"missing_cast_columns\"]\n",
    "for c in new_cols:\n",
    "    if c in df_asn.columns:\n",
    "        # avoid accidental overwrite\n",
    "        df_asn.drop(columns=[c], inplace=True)\n",
    "\n",
    "# --------------------\n",
    "# Row-wise quantification\n",
    "# --------------------\n",
    "results = []\n",
    "for idx, row in df_asn.iterrows():\n",
    "    bin_value = float(row[\"bin\"])\n",
    "    mz_list = parse_mz_list(row[\"matched_mz_list\"])\n",
    "    cast_cols = [to_cast_col(mz) for mz in mz_list]\n",
    "\n",
    "    # Filter dataset_rt to this bin\n",
    "    df_bin = df_rt[df_rt[\"bin\"] == bin_value]\n",
    "    if df_bin.empty:\n",
    "        res = dict(\n",
    "            group_0_sum=float(\"nan\"),\n",
    "            group_1_sum=float(\"nan\"),\n",
    "            group_2_sum=float(\"nan\"),\n",
    "            group_3_sum=float(\"nan\"),\n",
    "            n_mz_used=len(cast_cols),\n",
    "            n_mz_found=0,\n",
    "            missing_cast_columns=\", \".join(cast_cols) if cast_cols else \"\"\n",
    "        )\n",
    "        results.append(res)\n",
    "        continue\n",
    "\n",
    "    # Ensure target present\n",
    "    if \"target\" not in df_bin.columns:\n",
    "        raise KeyError(\"Column 'target' not found in dataset_rt.csv\")\n",
    "\n",
    "    existing = [c for c in cast_cols if c in df_bin.columns]\n",
    "    missing = [c for c in cast_cols if c not in df_bin.columns]\n",
    "\n",
    "    if not existing:\n",
    "        sums = {0: float(\"nan\"), 1: float(\"nan\"), 2: float(\"nan\"), 3: float(\"nan\")}\n",
    "    else:\n",
    "        # Sum intensities across all selected cast_* columns per target\n",
    "        grouped = df_bin.groupby(\"target\")[existing].sum()\n",
    "        total_per_target = grouped.sum(axis=1)  # sum across those cast_* columns\n",
    "        sums = {t: float(total_per_target.get(t, float(\"nan\"))) for t in [0, 1, 2, 3]}\n",
    "\n",
    "    res = dict(\n",
    "        group_0_sum=sums[0],\n",
    "        group_1_sum=sums[1],\n",
    "        group_2_sum=sums[2],\n",
    "        group_3_sum=sums[3],\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "# Attach results\n",
    "df_quant = pd.DataFrame(results, index=df_asn.index)\n",
    "df_asn_out = pd.concat([df_asn, df_quant], axis=1)\n",
    "\n",
    "# --------------------\n",
    "# Save updated CSV\n",
    "# --------------------\n",
    "df_asn_out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"Saved: {OUT_PATH}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
