{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d94c968a",
   "metadata": {},
   "source": [
    "Functions to generate MS1 and MS2 matrixes plus metadata from rawfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99980ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from fisher_py.data.business import Scan\n",
    "from fisher_py import RawFile\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Config / binning\n",
    "# -----------------------------\n",
    "MS1_MIN_IDX, MS1_LEN = 6000, 13690   # 600.0 m/z * 10 .. 1935.9 (10 pts per m/z)\n",
    "MS1_MAX_EXC = MS1_MIN_IDX + MS1_LEN\n",
    "MS2_MIN_IDX, MS2_LEN = 400, 1600     # m/z 400..1999 (1 pt per m/z)\n",
    "MS2_MAX_EXC = MS2_MIN_IDX + MS2_LEN\n",
    "\n",
    "GROUPS = (\"TreatmentA\", \"TreatmentB\", \"TreatmentC\", \"TreatmentD\")\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def _scan_type_label(text: str) -> str:\n",
    "    m = re.search(r\"Full\\s+(\\w+)\", str(text), flags=re.IGNORECASE)\n",
    "    return m.group(1).lower() if m else \"\"\n",
    "\n",
    "def _group_from_name(name: str) -> str:\n",
    "    for g in GROUPS:\n",
    "        if g in name:\n",
    "            return g\n",
    "    return \"Unknown\"\n",
    "\n",
    "def _as_float_array(x):\n",
    "    if x is None:\n",
    "        return np.array([], dtype=float)\n",
    "    a = np.asarray(x)\n",
    "    return a.astype(float, copy=False) if a.size else np.array([], dtype=float)\n",
    "\n",
    "def _ensure_folder_list(paths):\n",
    "    if isinstance(paths, (list, tuple)):\n",
    "        return list(paths)\n",
    "    return [paths]\n",
    "\n",
    "def _gather_raw_files(folder_paths):\n",
    "    folder_list = _ensure_folder_list(folder_paths)\n",
    "    raw_files = []\n",
    "    for fp in folder_list:\n",
    "        fp_abs = os.path.abspath(fp)\n",
    "        if not os.path.isdir(fp_abs):\n",
    "            raise FileNotFoundError(f'Folder not found: \"{fp_abs}\"')\n",
    "        raw_files.extend(glob.glob(os.path.join(fp_abs, \"*.raw\")))\n",
    "        raw_files.extend(glob.glob(os.path.join(fp_abs, \"*.RAW\")))\n",
    "    raw_files = sorted(set(os.path.abspath(p) for p in raw_files))\n",
    "    if not raw_files:\n",
    "        raise FileNotFoundError(\n",
    "            f'No \".raw\" files found in: {\", \".join(map(os.path.abspath, folder_list))}'\n",
    "        )\n",
    "    return raw_files\n",
    "\n",
    "def _sanitize_metadata_dict(md: dict) -> dict:\n",
    "    \"\"\"Ensure arrays are numeric or Unicode (never object dtype).\"\"\"\n",
    "    safe = {}\n",
    "    for k, v in md.items():\n",
    "        if isinstance(v, (int, float, np.number, np.bool_)):\n",
    "            safe[k] = np.array(v)\n",
    "            continue\n",
    "        if isinstance(v, (list, tuple, np.ndarray)):\n",
    "            arr = np.asarray(v)\n",
    "            if arr.dtype == object:\n",
    "                try:\n",
    "                    arr = arr.astype(np.float32)\n",
    "                except Exception:\n",
    "                    arr = arr.astype(\"U\")\n",
    "            if np.issubdtype(arr.dtype, np.character):\n",
    "                arr = arr.astype(\"U\")\n",
    "            safe[k] = arr\n",
    "            continue\n",
    "        if isinstance(v, str):\n",
    "            safe[k] = np.array(v, dtype=\"U\")\n",
    "            continue\n",
    "        safe[k] = np.array(str(v), dtype=\"U\")\n",
    "    return safe\n",
    "\n",
    "def _out_paths(out_dir: str, group: str):\n",
    "    base = os.path.join(os.path.abspath(out_dir), group)\n",
    "    return (f\"{base}.ms1.npz\", f\"{base}.ms2.npz\", f\"{base}.meta.npz\")\n",
    "\n",
    "# -----------------------------\n",
    "# Core: process one treatment group at a time\n",
    "# -----------------------------\n",
    "def _process_group(group: str, group_files: list, out_dir: str):\n",
    "    \"\"\"\n",
    "    Builds:\n",
    "      - MS1 (float32, UNnormalized) stacked per MS1 scan for this group\n",
    "      - MS2 (float16, per-scan normalized) stacked per MS2 scan for this group\n",
    "      - METADATA aligned to the two matrices\n",
    "    Saves three NPZ files and frees RAM.\n",
    "    \"\"\"\n",
    "    if not group_files:\n",
    "        return None\n",
    "\n",
    "    # Guard: require fisher_py\n",
    "    try:\n",
    "        RawFile, Scan  # type: ignore # noqa\n",
    "    except NameError:\n",
    "        raise ImportError(\"fisher_py is required for RAW access. Uncomment the imports at the top.\")\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    ms1_path, ms2_path, meta_path = _out_paths(out_dir, group)\n",
    "\n",
    "    # Per-group accumulators\n",
    "    file_basenames, file_abspaths = [], []\n",
    "    file_to_id = {}\n",
    "\n",
    "    # MS1\n",
    "    ms1_rows = []                               # list of vectors (float32)\n",
    "    ms1_scan, ms1_rt, ms1_file_id = [], [], []  # aligned to ms1_rows\n",
    "\n",
    "    # MS2\n",
    "    ms2_rows = []                               # list of vectors (float16)\n",
    "    ms2_scan, ms2_rt, ms2_prec_mz, ms2_file_id = [], [], [], []\n",
    "\n",
    "    # Iterate files in this group\n",
    "    for raw_abs in group_files:\n",
    "        raw_name = os.path.basename(raw_abs)\n",
    "        if raw_abs not in file_to_id:\n",
    "            file_to_id[raw_abs] = len(file_basenames)\n",
    "            file_basenames.append(raw_name)\n",
    "            file_abspaths.append(raw_abs)\n",
    "        f_id = file_to_id[raw_abs]\n",
    "\n",
    "        # open RAW\n",
    "        try:\n",
    "            raw = RawFile(raw_abs)\n",
    "        except Exception as e:\n",
    "            print(f'[skip] Cannot open RAW: {raw_abs} ({e})')\n",
    "            continue\n",
    "\n",
    "        total_scans = int(getattr(raw, \"number_of_scans\", 0) or 0)\n",
    "\n",
    "        for i in tqdm(range(1, total_scans + 1), desc=f\"[{group}] {raw_name}\", ncols=100):\n",
    "            try:\n",
    "                raw_scan = Scan.from_file(raw._raw_file_access, scan_number=i)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            stype = _scan_type_label(raw_scan.scan_type)\n",
    "            sc_num = getattr(raw_scan.scan_statistics, \"scan_number\", i)\n",
    "            try:\n",
    "                rt = float(raw.get_retention_time_from_scan_number(sc_num))\n",
    "            except Exception:\n",
    "                rt = np.nan\n",
    "\n",
    "            masses = _as_float_array(getattr(raw_scan, \"preferred_masses\", None))\n",
    "            intens = _as_float_array(getattr(raw_scan, \"preferred_intensities\", None))\n",
    "            if masses.size == 0 or intens.size == 0:\n",
    "                continue\n",
    "\n",
    "            if stype == \"ms\":\n",
    "                # Build UNnormalized float32 MS1 row\n",
    "                # Bin at 0.1 m/z: index = round(m/z*10)\n",
    "                idx = np.rint(masses * 10.0).astype(np.int32)\n",
    "                mask = (idx >= MS1_MIN_IDX) & (idx < MS1_MAX_EXC)\n",
    "                if not mask.any():\n",
    "                    continue\n",
    "                v32 = np.zeros(MS1_LEN, dtype=np.float32)\n",
    "                np.add.at(v32, idx[mask] - MS1_MIN_IDX, intens[mask].astype(np.float32, copy=False))\n",
    "                ms1_rows.append(v32)\n",
    "                ms1_scan.append(sc_num)\n",
    "                ms1_rt.append(rt)\n",
    "                ms1_file_id.append(f_id)\n",
    "\n",
    "            elif stype == \"ms2\":\n",
    "                # Build per-scan normalized MS2 row (float16 for compact size)\n",
    "                # Bin at 1.0 m/z: index = round(m/z)\n",
    "                idx = np.rint(masses).astype(np.int32)\n",
    "                mask = (idx >= MS2_MIN_IDX) & (idx < MS2_MAX_EXC)\n",
    "                if not mask.any():\n",
    "                    continue\n",
    "                v32 = np.zeros(MS2_LEN, dtype=np.float32)\n",
    "                np.add.at(v32, idx[mask] - MS2_MIN_IDX, intens[mask].astype(np.float32, copy=False))\n",
    "                vmax = float(v32.max())\n",
    "                if vmax > 0:\n",
    "                    v32 /= vmax\n",
    "                vec_ms2 = v32.astype(np.float16, copy=False)\n",
    "\n",
    "                # Precursor m/z (fallback to parsing scan_type text)\n",
    "                prec = np.nan\n",
    "                for attr in (\"precursor_mz\", \"master_precursor_mz\", \"isolation_mz\"):\n",
    "                    if hasattr(raw_scan, attr):\n",
    "                        try:\n",
    "                            prec = float(getattr(raw_scan, attr))\n",
    "                            break\n",
    "                        except Exception:\n",
    "                            pass\n",
    "                if np.isnan(prec):\n",
    "                    m = re.findall(r'\\d+\\.\\d+', str(raw_scan.scan_type))\n",
    "                    prec = float(m[1]) if len(m) > 1 else np.nan\n",
    "\n",
    "                ms2_rows.append(vec_ms2)\n",
    "                ms2_scan.append(sc_num)\n",
    "                ms2_rt.append(rt)\n",
    "                ms2_prec_mz.append(prec)\n",
    "                ms2_file_id.append(f_id)\n",
    "\n",
    "        # dispose RAW handle\n",
    "        try:\n",
    "            raw.dispose()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # ---- Build metadata (per-group) ----\n",
    "    # Note: IDs are per-group (0..n_files_in_group-1)\n",
    "    metadata_raw = dict(\n",
    "        group_name=np.array(group, dtype=\"U\"),\n",
    "\n",
    "        # MS1 row-aligned meta\n",
    "        ms1_scan=np.asarray(ms1_scan, dtype=np.int32),\n",
    "        ms1_rt=np.asarray(ms1_rt, dtype=np.float32),\n",
    "        ms1_file_id=np.asarray(ms1_file_id, dtype=np.int32),\n",
    "\n",
    "        # MS2 row-aligned meta\n",
    "        ms2_scan=np.asarray(ms2_scan, dtype=np.int32),\n",
    "        ms2_rt=np.asarray(ms2_rt, dtype=np.float32),\n",
    "        ms2_precursor_mz=np.asarray(ms2_prec_mz, dtype=np.float32),\n",
    "        ms2_file_id=np.asarray(ms2_file_id, dtype=np.int32),\n",
    "\n",
    "        # Lookups\n",
    "        file_names_lookup=np.asarray(file_basenames, dtype=\"U\"),\n",
    "        file_paths_lookup=np.asarray(file_abspaths, dtype=\"U\"),\n",
    "    )\n",
    "    metadata = _sanitize_metadata_dict(metadata_raw)\n",
    "\n",
    "    # ---- Stack & save (release RAM right after) ----\n",
    "    # MS1 (float32, UNnormalized)\n",
    "    if ms1_rows:\n",
    "        MS1 = np.vstack(ms1_rows).astype(np.float32, copy=False)\n",
    "    else:\n",
    "        MS1 = np.zeros((0, MS1_LEN), dtype=np.float32)\n",
    "    np.savez_compressed(ms1_path, ms1_matrix=MS1, **metadata)\n",
    "    print(f\"[{group}] Saved MS1: {ms1_path}  shape={MS1.shape}, dtype={MS1.dtype}\")\n",
    "    del MS1, ms1_rows\n",
    "    gc.collect()\n",
    "\n",
    "    # MS2 (float16, normalized per scan)\n",
    "    if ms2_rows:\n",
    "        MS2 = np.vstack(ms2_rows).astype(np.float16, copy=False)\n",
    "    else:\n",
    "        MS2 = np.zeros((0, MS2_LEN), dtype=np.float16)\n",
    "    np.savez_compressed(ms2_path, ms2_matrix=MS2, **metadata)\n",
    "    print(f\"[{group}] Saved MS2: {ms2_path}  shape={MS2.shape}, dtype={MS2.dtype}\")\n",
    "    del MS2, ms2_rows\n",
    "    gc.collect()\n",
    "\n",
    "    # Save metadata standalone (useful if you want to load meta without matrices)\n",
    "    np.savez_compressed(meta_path, **metadata)\n",
    "    print(f\"[{group}] Saved META: {meta_path}\")\n",
    "\n",
    "    # Final cleanup\n",
    "    del metadata, metadata_raw\n",
    "    gc.collect()\n",
    "\n",
    "    return {\"group\": group, \"ms1\": ms1_path, \"ms2\": ms2_path, \"meta\": meta_path}\n",
    "\n",
    "# -----------------------------\n",
    "# Public API\n",
    "# -----------------------------\n",
    "def wholeCasting_per_group(folder_paths, out_dir: str):\n",
    "    \"\"\"\n",
    "    Scans RAW files, partitions by TreatmentA/B/C/D (using filename contains),\n",
    "    and for each group writes:\n",
    "      <out_dir>/<Group>.ms1.npz  (float32, UNnormalized)\n",
    "      <out_dir>/<Group>.ms2.npz  (float16, per-scan normalized)\n",
    "      <out_dir>/<Group>.meta.npz\n",
    "\n",
    "    RAM is freed between groups.\n",
    "    Returns a dict of outputs keyed by group.\n",
    "    \"\"\"\n",
    "    raw_files = _gather_raw_files(folder_paths)\n",
    "    by_group = {g: [] for g in GROUPS}\n",
    "    for p in raw_files:\n",
    "        g = _group_from_name(os.path.basename(p))\n",
    "        if g in by_group:\n",
    "            by_group[g].append(p)\n",
    "\n",
    "    outputs = {}\n",
    "    for g in GROUPS:\n",
    "        paths = _process_group(g, by_group[g], out_dir)\n",
    "        outputs[g] = paths\n",
    "        # safety: ensure memory is really freed between groups\n",
    "        gc.collect()\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9588164d",
   "metadata": {},
   "source": [
    "Calling the wrapper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95399297",
   "metadata": {},
   "outputs": [],
   "source": [
    "wholeCasting_per_group([\"F:/TreatmentABC\", \"F:/TreatmentD\"], out_dir=\"F:/casts/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bccfb3",
   "metadata": {},
   "source": [
    "Clean the RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b72e2760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this will wipe *everything* you defined in the current session!\n",
    "for var in list(globals().keys()):\n",
    "    if var[0] != \"_\":  # keep built-ins like __name__, __doc__, etc.\n",
    "        del globals()[var]\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd828755",
   "metadata": {},
   "source": [
    "Combine MS2 matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa466f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "TreatmentA = \"F:/casts/databank/TreatmentA.ms2.npz\"\n",
    "TreatmentB = \"F:/casts/databank/TreatmentB.ms2.npz\"\n",
    "TreatmentC = \"F:/casts/databank/TreatmentC.ms2.npz\"\n",
    "TreatmentD = \"F:/casts/databank/TreatmentD.ms2.npz\"\n",
    "\n",
    "z = np.load(file=TreatmentD)\n",
    "\n",
    "# Mat + metadata (same row count/order)\n",
    "ms2_D = z[\"ms2_matrix\"]             # (n_rows, 13690), float32\n",
    "ms2_scan = z[\"ms2_scan\"]          # (n_rows,)\n",
    "ms2_rt   = z[\"ms2_rt\"]            # (n_rows,) minutes\n",
    "ms2_fid  = z[\"ms2_file_id\"]       # (n_rows,)\n",
    "fnames   = z[\"file_names_lookup\"] # (n_files,)\n",
    "group_name = z[\"group_name\"]\n",
    "precursor_mz = z[\"ms2_precursor_mz\"]\n",
    "\n",
    "# Optional: assemble a handy DataFrame aligned to ms1 rows\n",
    "ms2_meta_D = pd.DataFrame({\n",
    "    \"scan\": ms2_scan,\n",
    "    \"rt_min\": ms2_rt,\n",
    "    \"precursor_mz\": precursor_mz,\n",
    "    \"file_name\": fnames[ms2_fid],\n",
    "    'group_name': group_name\n",
    "})\n",
    "\n",
    "metadata = pd.concat([ms2_meta_A, ms2_meta_B, ms2_meta_C, ms2_meta_D], ignore_index=True)\n",
    "ms2_lib = np.vstack((ms2_A, ms2_B, ms2_C, ms2_D))\n",
    "\n",
    "\n",
    "\n",
    "with h5py.File(\"F:/casts/databank/ms2_dataset.h5\", \"w\") as f:\n",
    "    f.create_dataset(\"ms2_lib\", data=ms2_lib, compression=\"gzip\")\n",
    "    for col in metadata.columns:\n",
    "        f.create_dataset(col, data=metadata[col].values.astype(\"S\") if metadata[col].dtype == object else metadata[col].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2127320",
   "metadata": {},
   "source": [
    "Upload the MS2 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f13d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "with h5py.File(\"F:/casts/databank/ms2_dataset.h5\", \"r\") as f:\n",
    "    ms2_lib = f[\"ms2_lib\"][:]\n",
    "    metadata = pd.DataFrame({col: f[col][:] for col in f.keys() if col != \"ms2_lib\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ca29b4",
   "metadata": {},
   "source": [
    "Generate the drift table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b790be13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220315_chm134_Cirrhosis_FlowChip15_AA13001EM1_TreatmentA_biorep01_techrep02.raw: weighted overall avg drift = -0.331 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA13001EM1_TreatmentA_biorep01_techrep03.raw: weighted overall avg drift = -0.961 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep01.raw: weighted overall avg drift = 1.789 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep02.raw: weighted overall avg drift = 1.816 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep03.raw: weighted overall avg drift = 1.985 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep01.raw: weighted overall avg drift = -0.387 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep02.raw: weighted overall avg drift = -0.682 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep03.raw: weighted overall avg drift = -0.689 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep01.raw: weighted overall avg drift = -1.035 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep02.raw: weighted overall avg drift = -0.611 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep03.raw: weighted overall avg drift = -0.136 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep01.raw: weighted overall avg drift = 0.872 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep02.raw: weighted overall avg drift = 1.195 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep03.raw: weighted overall avg drift = 0.509 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep01.raw: weighted overall avg drift = 6.001 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep02.raw: weighted overall avg drift = 5.437 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep03.raw: weighted overall avg drift = 4.507 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep01.raw: weighted overall avg drift = 8.276 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep02.raw: weighted overall avg drift = 8.668 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep03.raw: weighted overall avg drift = 8.304 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep01.raw: weighted overall avg drift = 9.623 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep02.raw: weighted overall avg drift = 9.703 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep03.raw: weighted overall avg drift = 9.141 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep01.raw: weighted overall avg drift = 6.439 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep02.raw: weighted overall avg drift = 6.500 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep03.raw: weighted overall avg drift = 6.819 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep01.raw: weighted overall avg drift = 10.328 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep02.raw: weighted overall avg drift = 10.092 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep03.raw: weighted overall avg drift = 10.087 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep01.raw: weighted overall avg drift = 0.498 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep02.raw: weighted overall avg drift = 0.164 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep03.raw: weighted overall avg drift = 0.203 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep01.raw: weighted overall avg drift = -1.899 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep02.raw: weighted overall avg drift = -1.461 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep03.raw: weighted overall avg drift = -2.622 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep01.raw: weighted overall avg drift = -0.173 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep02.raw: weighted overall avg drift = -0.213 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep03.raw: weighted overall avg drift = -0.297 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep01.raw: weighted overall avg drift = 0.063 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep02.raw: weighted overall avg drift = 0.254 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep03.raw: weighted overall avg drift = -0.041 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep01.raw: weighted overall avg drift = 0.689 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep02.raw: weighted overall avg drift = 0.867 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep03.raw: weighted overall avg drift = 0.682 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep01.raw: weighted overall avg drift = 0.087 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep02.raw: weighted overall avg drift = -0.190 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep03.raw: weighted overall avg drift = -0.188 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep01.raw: weighted overall avg drift = 0.117 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep02.raw: weighted overall avg drift = 0.828 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep03.raw: weighted overall avg drift = 0.409 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep01.raw: weighted overall avg drift = 4.593 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep02.raw: weighted overall avg drift = 5.093 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep03.raw: weighted overall avg drift = 3.931 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep01.raw: weighted overall avg drift = 5.951 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep02.raw: weighted overall avg drift = 6.896 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep03.raw: weighted overall avg drift = 6.180 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep01.raw: weighted overall avg drift = 6.260 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep02.raw: weighted overall avg drift = 6.817 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep03.raw: weighted overall avg drift = 6.346 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep01.raw: weighted overall avg drift = 8.255 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep02.raw: weighted overall avg drift = 8.224 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep03.raw: weighted overall avg drift = 8.832 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep01.raw: weighted overall avg drift = -0.419 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep02.raw: weighted overall avg drift = -1.205 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep03.raw: weighted overall avg drift = -1.496 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep01.raw: weighted overall avg drift = -1.360 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep02.raw: weighted overall avg drift = -1.008 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep03.raw: weighted overall avg drift = -1.038 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep01.raw: weighted overall avg drift = 0.193 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep02.raw: weighted overall avg drift = -0.002 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep03.raw: weighted overall avg drift = -1.077 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep01.raw: weighted overall avg drift = 0.215 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep02.raw: weighted overall avg drift = -0.186 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep03.raw: weighted overall avg drift = 0.017 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY2025EM1_TreatmentC_biorep25_techrep01.raw: weighted overall avg drift = 0.071 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY2025EM1_TreatmentC_biorep25_techrep03.raw: weighted overall avg drift = -0.381 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep01.raw: weighted overall avg drift = -0.286 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep02.raw: weighted overall avg drift = 0.353 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep03.raw: weighted overall avg drift = 0.239 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep01.raw: weighted overall avg drift = 7.943 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep02.raw: weighted overall avg drift = 7.347 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep03.raw: weighted overall avg drift = 7.320 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep01.raw: weighted overall avg drift = 4.870 min (kept 5 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep02.raw: weighted overall avg drift = 5.213 min (kept 5 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep03.raw: weighted overall avg drift = 4.340 min (kept 5 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep01.raw: weighted overall avg drift = 6.853 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep02.raw: weighted overall avg drift = 7.048 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep03.raw: weighted overall avg drift = 6.500 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep01.raw: weighted overall avg drift = -0.854 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep02.raw: weighted overall avg drift = -0.883 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep03.raw: weighted overall avg drift = -0.911 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep38_techrep03.raw: weighted overall avg drift = 0.172 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep01.raw: weighted overall avg drift = 1.399 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep02.raw: weighted overall avg drift = 2.757 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep03.raw: weighted overall avg drift = 3.209 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AG2638BC1_TreatmentD_biorep38_techrep01.raw: weighted overall avg drift = 0.543 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AG2638BC1_TreatmentD_biorep38_techrep02.raw: weighted overall avg drift = 0.255 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep01.raw: weighted overall avg drift = 1.571 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep02.raw: weighted overall avg drift = 1.286 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep03.raw: weighted overall avg drift = 1.494 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep01.raw: weighted overall avg drift = 2.145 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep02.raw: weighted overall avg drift = 1.328 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep03.raw: weighted overall avg drift = 2.224 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep01.raw: weighted overall avg drift = 0.918 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep02.raw: weighted overall avg drift = 1.133 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep03.raw: weighted overall avg drift = 1.436 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep01.raw: weighted overall avg drift = 4.469 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep02.raw: weighted overall avg drift = 5.343 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep03.raw: weighted overall avg drift = 4.751 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep01.raw: weighted overall avg drift = 8.526 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep02.raw: weighted overall avg drift = 8.332 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep03.raw: weighted overall avg drift = 8.547 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AG2637BC1_TreatmentD_biorep37_techrep01.raw: weighted overall avg drift = 7.077 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AG2637BC1_TreatmentD_biorep37_techrep02.raw: weighted overall avg drift = 6.493 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep01.raw: weighted overall avg drift = 6.717 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep02.raw: weighted overall avg drift = 7.482 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep03.raw: weighted overall avg drift = 7.421 min (kept 8 bins with ≥1 valid match; TARGET_N=50)\n",
      "Saved aligned metadata to: F:/casts/databank/aligned_metadata1.csv\n",
      "Saved per-bin RT drifts to: F:/casts/databank/rt_drifts1.csv\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA13001EM1_TreatmentA_biorep01_techrep01.raw median correction:  0.000 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA13001EM1_TreatmentA_biorep01_techrep02.raw median correction: -0.319 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA13001EM1_TreatmentA_biorep01_techrep03.raw median correction: -1.006 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep01.raw median correction:  1.849 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep02.raw median correction:  2.051 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AA26021EM1_TreatmentA_biorep21_techrep03.raw median correction:  1.804 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep01.raw median correction: -0.365 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep02.raw median correction: -0.007 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA18009EM1_TreatmentA_biorep09_techrep03.raw median correction: -0.440 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep01.raw median correction: -1.179 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep02.raw median correction: -1.088 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AA18011EM1_TreatmentA_biorep11_techrep03.raw median correction: -0.472 min\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep01.raw median correction:  2.885 min\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep02.raw median correction:  2.918 min\n",
      "20220403_chm134_Cirrhosis_FlowChip15_AA26017EM1_TreatmentA_biorep17_techrep03.raw median correction:  1.379 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep01.raw median correction:  7.457 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep02.raw median correction:  7.399 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15004EM1_TreatmentA_biorep04_techrep03.raw median correction:  7.779 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep01.raw median correction:  9.113 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep02.raw median correction:  9.386 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA15008EM1_TreatmentA_biorep08_techrep03.raw median correction:  9.130 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep01.raw median correction:  9.889 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep02.raw median correction:  9.592 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AY13033EM1_TreatmentA_biorep33_techrep03.raw median correction:  9.663 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep01.raw median correction:  7.787 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep02.raw median correction:  7.723 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA18010EM1_TreatmentA_biorep10_techrep03.raw median correction:  7.837 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep01.raw median correction:  9.713 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep02.raw median correction:  9.581 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15003EM1_TreatmentA_biorep03_techrep03.raw median correction:  10.356 min\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep01.raw median correction:  1.910 min\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep02.raw median correction:  2.346 min\n",
      "20230403_chm134_Cirrhosis_FlowChip15_AA26016EM1_TreatmentA_biorep16_techrep03.raw median correction:  0.685 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep01.raw median correction: -1.968 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep02.raw median correction: -1.727 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA26018EM1_TreatmentB_biorep18_techrep03.raw median correction: -1.806 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep01.raw median correction: -0.597 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep02.raw median correction: -0.720 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6027EM1_TreatmentB_biorep27_techrep03.raw median correction: -0.569 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep01.raw median correction: -0.298 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep02.raw median correction:  0.093 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AY2023EM1_TreatmentB_biorep23_techrep03.raw median correction: -0.111 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep01.raw median correction:  0.500 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep02.raw median correction:  0.456 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY6029EM1_TreatmentB_biorep29_techrep03.raw median correction:  0.745 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep01.raw median correction:  0.379 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep02.raw median correction: -0.269 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY6026EM1_TreatmentB_biorep26_techrep03.raw median correction:  0.260 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep01.raw median correction:  0.849 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep02.raw median correction:  1.354 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AY12031EM1_TreatmentB_biorep31_techrep03.raw median correction:  0.794 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep01.raw median correction:  8.576 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep02.raw median correction:  7.832 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AY2024EM1_TreatmentB_biorep24_techrep03.raw median correction:  7.973 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep01.raw median correction:  7.077 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep02.raw median correction:  8.402 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AA14002EM1_TreatmentB_biorep02_techrep03.raw median correction:  8.106 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep01.raw median correction:  7.085 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep02.raw median correction:  8.143 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AA2022EM1_TreatmentB_biorep22_techrep03.raw median correction:  6.990 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep01.raw median correction:  9.428 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep02.raw median correction:  9.487 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA15007EM1_TreatmentB_biorep07_techrep03.raw median correction:  9.955 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep01.raw median correction: -0.231 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep02.raw median correction: -1.769 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AA21013EM1_TreatmentC_biorep13_techrep03.raw median correction: -2.060 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep01.raw median correction: -1.379 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep02.raw median correction: -1.526 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AY6028EM1_TreatmentC_biorep28_techrep03.raw median correction: -1.352 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep01.raw median correction: -0.102 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep02.raw median correction:  0.087 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AA21014EM1_TreatmentC_biorep14_techrep03.raw median correction: -0.139 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep01.raw median correction: -0.252 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep02.raw median correction: -0.510 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AY9030EM1_TreatmentC_biorep30_techrep03.raw median correction: -0.023 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY2025EM1_TreatmentC_biorep25_techrep01.raw median correction:  0.008 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AY2025EM1_TreatmentC_biorep25_techrep03.raw median correction:  0.083 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep01.raw median correction:  0.373 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep02.raw median correction:  0.095 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AU3034EM1_TreatmentC_biorep34_techrep03.raw median correction:  0.639 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep01.raw median correction:  9.072 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep02.raw median correction:  8.295 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AA15006EM1_TreatmentC_biorep06_techrep03.raw median correction:  8.514 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep01.raw median correction:  8.090 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep02.raw median correction:  12.127 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AY12032EM1_TreatmentC_biorep32_techrep03.raw median correction:  9.342 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep01.raw median correction:  8.812 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep02.raw median correction:  8.599 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AA21012EM1_TreatmentC_biorep12_techrep03.raw median correction:  8.797 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep01.raw median correction: -1.417 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep02.raw median correction: -0.927 min\n",
      "20220315_chm134_Cirrhosis_FlowChip15_AG2635BC1_TreatmentD_biorep35_techrep03.raw median correction: -1.230 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep38_techrep03.raw median correction: -0.010 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep01.raw median correction: -0.028 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep02.raw median correction:  1.057 min\n",
      "20220317_chm134_Cirrhosis_FlowChip15_AG2639BC1_TreatmentD_biorep39_techrep03.raw median correction:  0.580 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AG2638BC1_TreatmentD_biorep38_techrep01.raw median correction:  0.418 min\n",
      "20220320_chm134_Cirrhosis_FlowChip15_AG2638BC1_TreatmentD_biorep38_techrep02.raw median correction: -0.177 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep01.raw median correction:  1.785 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep02.raw median correction:  1.477 min\n",
      "20220322_chm134_Cirrhosis_FlowChip15_AG31050BC1_TreatmentD_biorep50_techrep03.raw median correction:  1.130 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep01.raw median correction:  2.530 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep02.raw median correction:  2.140 min\n",
      "20220329_chm134_Cirrhosis_FlowChip15_AG31046BC1_TreatmentD_biorep46_techrep03.raw median correction:  2.850 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep01.raw median correction:  2.322 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep02.raw median correction:  1.291 min\n",
      "20220330_chm134_Cirrhosis_FlowChip15_AG31048BC1_TreatmentD_biorep48_techrep03.raw median correction:  1.889 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep01.raw median correction:  7.791 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep02.raw median correction:  8.229 min\n",
      "20221103_chm134_Cirrhosis_FlowChip15_AG31049BC1_TreatmentD_biorep49_techrep03.raw median correction:  7.760 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep01.raw median correction:  8.752 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep02.raw median correction:  8.443 min\n",
      "20221105_chm134_Cirrhosis_FlowChip15_AG31047BC1_TreatmentD_biorep47_techrep03.raw median correction:  8.868 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AG2637BC1_TreatmentD_biorep37_techrep01.raw median correction:  8.550 min\n",
      "20221108_chm134_Cirrhosis_FlowChip15_AG2637BC1_TreatmentD_biorep37_techrep02.raw median correction:  8.276 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep01.raw median correction:  9.299 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep02.raw median correction:  8.690 min\n",
      "20221111_chm134_Cirrhosis_FlowChip15_AG2640BC1_TreatmentD_biorep40_techrep03.raw median correction:  8.653 min\n",
      "\n",
      "Columns in aligned_df:\n",
      "  sample_name, m/z, retntion time, rt_correction, rt_aligned, cast spectra\n",
      "\n",
      "Drift table columns:\n",
      "['bin_start_min', 'bin_end_min', 'expanded_start_min', 'expanded_end_min', 'n_in_expanded_window', 'n_valid_used', 'target_n', 'avg_rt_drift', 'bin_center_min', 'target_name']\n",
      "Saved drift matrix (runs × bins) to: F:/casts/databank/rt_drifts_matrix1.csv\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Load HDF5 (ms2_dataset.h5) -> compute per-bin RT drifts vs first run -> align RTs\n",
    "Save:\n",
    "  - per-scan aligned metadata CSV (drops 'cast spectra')\n",
    "  - per-bin drift tables CSV\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from math import floor, ceil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================\n",
    "# Config\n",
    "# =====================\n",
    "H5_PATH = r\"F:/casts/databank/ms2_dataset.h5\"\n",
    "\n",
    "SIM_THRESHOLD  = 0.95\n",
    "MZ_WINDOW      = 1.0\n",
    "TARGET_N       = 50\n",
    "BIN_WIDTH      = 10.0\n",
    "OVERLAP_MIN    = 2.5\n",
    "FORCE_BIN_END_MIN = 80.0\n",
    "SAMPLE_WITH_REPLACEMENT_IF_NEEDED = False\n",
    "\n",
    "PLOT_DRIFT_CURVES = False     # set True if you want plots\n",
    "PLOT_SANITY_AFTER = False\n",
    "\n",
    "# CSV outputs\n",
    "SAVE_ALIGNED_CSV  = True\n",
    "CSV_OUT_PATH      = r\"F:/casts/databank/aligned_metadata1.csv\"\n",
    "\n",
    "SAVE_DRIFTS_CSV   = True\n",
    "DRIFTS_CSV_PATH   = r\"F:/casts/databank/rt_drifts1.csv\"\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "def _to_1d_float_array(x):\n",
    "    if isinstance(x, np.ndarray):\n",
    "        arr = x\n",
    "    elif isinstance(x, (list, tuple)):\n",
    "        arr = np.asarray(x, dtype=float)\n",
    "    else:\n",
    "        try:\n",
    "            arr = np.asarray(x, dtype=float).ravel()\n",
    "        except Exception:\n",
    "            return None\n",
    "    return arr.ravel().astype(float, copy=False)\n",
    "\n",
    "def cosine(a, b):\n",
    "    va = _to_1d_float_array(a); vb = _to_1d_float_array(b)\n",
    "    if va is None or vb is None or va.size == 0 or vb.size == 0:\n",
    "        return -np.inf\n",
    "    if va.shape != vb.shape:\n",
    "        n = min(va.size, vb.size)\n",
    "        if n == 0:\n",
    "            return -np.inf\n",
    "        va, vb = va[:n], vb[:n]\n",
    "    denom = np.linalg.norm(va) * np.linalg.norm(vb)\n",
    "    if denom == 0:\n",
    "        return -np.inf\n",
    "    return float(np.dot(va, vb) / denom)\n",
    "\n",
    "def decode_bytes_inplace(df: pd.DataFrame) -> None:\n",
    "    for col in df.columns:\n",
    "        dt = df[col].dtype\n",
    "        if dt == object or str(dt).startswith(\"|S\"):\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: x.decode(\"utf-8\") if isinstance(x, (bytes, bytearray)) else x\n",
    "            )\n",
    "\n",
    "def pick_col(df: pd.DataFrame, *cands):\n",
    "    for c in cands:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    raise KeyError(f\"None of {cands} found. Available: {df.columns.tolist()}\")\n",
    "\n",
    "def harmonize_columns(df: pd.DataFrame) -> None:\n",
    "    # sample_name\n",
    "    if \"sample_name\" not in df.columns:\n",
    "        s_col = pick_col(df, \"sample_name\", \"file_name\", \"raw_name\", \"run_name\")\n",
    "        df[\"sample_name\"] = df[s_col].astype(str)\n",
    "\n",
    "    # m/z\n",
    "    if \"m/z\" not in df.columns:\n",
    "        mz_col = pick_col(df, \"m/z\", \"mz\", \"precursor_mz\")\n",
    "        df[\"m/z\"] = df[mz_col].astype(float)\n",
    "\n",
    "    # retntion time (keep original spelling for compatibility)\n",
    "    if \"retntion time\" not in df.columns:\n",
    "        if \"retention_time\" in df.columns:\n",
    "            df[\"retntion time\"] = df[\"retention_time\"].astype(float)\n",
    "        elif {\"rt_min\", \"rt_max\"}.issubset(df.columns):\n",
    "            df[\"retntion time\"] = (df[\"rt_min\"].astype(float) + df[\"rt_max\"].astype(float)) / 2.0\n",
    "        elif \"rt_min\" in df.columns:\n",
    "            df[\"retntion time\"] = df[\"rt_min\"].astype(float)\n",
    "        elif \"rt\" in df.columns:\n",
    "            df[\"retntion time\"] = df[\"rt\"].astype(float)\n",
    "        else:\n",
    "            raise KeyError(\"Could not infer 'retntion time' column from metadata.\")\n",
    "\n",
    "def load_h5_build_df(h5_path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(h5_path):\n",
    "        raise FileNotFoundError(h5_path)\n",
    "\n",
    "    with h5py.File(h5_path, \"r\") as f:\n",
    "        if \"ms2_lib\" not in f:\n",
    "            raise KeyError(\"HDF5 must contain 'ms2_lib' dataset.\")\n",
    "        ms2_lib = f[\"ms2_lib\"][:]  # (N, L)\n",
    "        meta = {k: f[k][:] for k in f.keys() if k != \"ms2_lib\"}\n",
    "\n",
    "    metadata = pd.DataFrame(meta)\n",
    "    decode_bytes_inplace(metadata)\n",
    "    harmonize_columns(metadata)\n",
    "\n",
    "    if len(metadata) != ms2_lib.shape[0]:\n",
    "        raise ValueError(f\"Row mismatch: metadata={len(metadata)} vs ms2_lib={ms2_lib.shape[0]}\")\n",
    "\n",
    "    metadata = metadata.copy()\n",
    "    metadata[\"cast spectra\"] = pd.Series(list(ms2_lib), index=metadata.index)\n",
    "    return metadata\n",
    "\n",
    "def build_bins_for_target(df_target: pd.DataFrame,\n",
    "                          bin_width: float,\n",
    "                          force_end_min):\n",
    "    if df_target.empty:\n",
    "        return [], np.nan, np.nan\n",
    "\n",
    "    rt_min = float(df_target[\"retntion time\"].min())\n",
    "    rt_max = float(df_target[\"retntion time\"].max())\n",
    "\n",
    "    start_edge = bin_width * floor(rt_min / bin_width)\n",
    "    end_edge   = bin_width * ceil(rt_max / bin_width)\n",
    "\n",
    "    if force_end_min is not None:\n",
    "        end_edge = float(force_end_min)\n",
    "        if end_edge <= start_edge:\n",
    "            raise ValueError(f\"FORCE_BIN_END_MIN ({force_end_min}) must be > start_edge ({start_edge}).\")\n",
    "\n",
    "    bins = []\n",
    "    t = start_edge\n",
    "    while t < end_edge:\n",
    "        bins.append((t, t + bin_width))\n",
    "        t += bin_width\n",
    "    return bins, rt_min, rt_max\n",
    "\n",
    "def collect_valid_drifts(bin_df: pd.DataFrame,\n",
    "                         mz_ref: np.ndarray,\n",
    "                         rt_ref: np.ndarray,\n",
    "                         cast_ref: np.ndarray,\n",
    "                         sim_threshold: float,\n",
    "                         mz_window: float,\n",
    "                         target_n: int,\n",
    "                         sample_with_replacement: bool) -> list:\n",
    "    if bin_df.empty:\n",
    "        return []\n",
    "\n",
    "    def drift_for_row(row):\n",
    "        mz_i   = float(row[\"m/z\"])\n",
    "        rt_i   = float(row[\"retntion time\"])\n",
    "        cast_i = row[\"cast spectra\"]\n",
    "\n",
    "        mask = np.abs(mz_ref - mz_i) < mz_window\n",
    "        idxs = np.where(mask)[0]\n",
    "        if idxs.size == 0:\n",
    "            return None\n",
    "\n",
    "        match_count = 0\n",
    "        rt_sum = 0.0\n",
    "        for j in idxs:\n",
    "            if cosine(cast_i, cast_ref[j]) > sim_threshold:\n",
    "                match_count += 1\n",
    "                rt_sum += rt_ref[j]\n",
    "        if match_count == 0:\n",
    "            return None\n",
    "        return rt_i - (rt_sum / match_count)\n",
    "\n",
    "    drifts = []\n",
    "    if sample_with_replacement:\n",
    "        tries = 0\n",
    "        max_tries = max(200, target_n * 20)\n",
    "        while len(drifts) < target_n and tries < max_tries:\n",
    "            row = bin_df.sample(n=1, replace=True).iloc[0]\n",
    "            tries += 1\n",
    "            d = drift_for_row(row)\n",
    "            if d is not None:\n",
    "                drifts.append(d)\n",
    "        return drifts\n",
    "\n",
    "    bin_df_shuf = bin_df.sample(frac=1.0, replace=False, random_state=42).reset_index(drop=True)\n",
    "    for _, row in bin_df_shuf.iterrows():\n",
    "        if len(drifts) >= target_n:\n",
    "            break\n",
    "        d = drift_for_row(row)\n",
    "        if d is not None:\n",
    "            drifts.append(d)\n",
    "    return drifts\n",
    "\n",
    "def compute_drift_table_for_target(df_target: pd.DataFrame,\n",
    "                                   mz_ref: np.ndarray,\n",
    "                                   rt_ref: np.ndarray,\n",
    "                                   cast_ref: np.ndarray) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    bins, rt_min, rt_max = build_bins_for_target(df_target, BIN_WIDTH, FORCE_BIN_END_MIN)\n",
    "    records = []\n",
    "\n",
    "    for (t0, t1) in bins:\n",
    "        win_start = max(t0 - OVERLAP_MIN, rt_min)\n",
    "        win_end   = min(t1 + OVERLAP_MIN, rt_max)\n",
    "\n",
    "        bin_df = df_target[(df_target[\"retntion time\"] >= win_start) &\n",
    "                           (df_target[\"retntion time\"] <  win_end)].copy()\n",
    "\n",
    "        drifts = collect_valid_drifts(\n",
    "            bin_df,\n",
    "            mz_ref=mz_ref, rt_ref=rt_ref, cast_ref=cast_ref,\n",
    "            sim_threshold=SIM_THRESHOLD,\n",
    "            mz_window=MZ_WINDOW,\n",
    "            target_n=TARGET_N,\n",
    "            sample_with_replacement=SAMPLE_WITH_REPLACEMENT_IF_NEEDED\n",
    "        )\n",
    "        n_valid = len(drifts)\n",
    "        avg_drift = float(np.mean(drifts)) if n_valid > 0 else float(\"nan\")\n",
    "\n",
    "        records.append({\n",
    "            \"bin_start_min\": t0,\n",
    "            \"bin_end_min\": t1,\n",
    "            \"expanded_start_min\": win_start,\n",
    "            \"expanded_end_min\": win_end,\n",
    "            \"n_in_expanded_window\": len(bin_df),\n",
    "            \"n_valid_used\": n_valid,\n",
    "            \"target_n\": TARGET_N,\n",
    "            \"avg_rt_drift\": avg_drift,\n",
    "        })\n",
    "\n",
    "    result_df = pd.DataFrame.from_records(records)\n",
    "    if result_df.empty:\n",
    "        return result_df, result_df\n",
    "\n",
    "    result_df[\"bin_center_min\"] = 0.5 * (result_df[\"bin_start_min\"] + result_df[\"bin_end_min\"])\n",
    "    plot_df_valid = result_df[\n",
    "        (~np.isnan(result_df[\"avg_rt_drift\"])) & (result_df[\"n_valid_used\"] > 0)\n",
    "    ].copy()\n",
    "    return result_df, plot_df_valid\n",
    "\n",
    "def build_alignment_function(plot_df_valid: pd.DataFrame):\n",
    "    if plot_df_valid is None or plot_df_valid.empty:\n",
    "        return lambda x: np.zeros_like(np.asarray(x, dtype=float))\n",
    "\n",
    "    x = plot_df_valid[\"bin_center_min\"].to_numpy()\n",
    "    y = plot_df_valid[\"avg_rt_drift\"].to_numpy()\n",
    "    order = np.argsort(x)\n",
    "    x = x[order]; y = y[order]\n",
    "\n",
    "    if x.size == 1:\n",
    "        c = float(y[0])\n",
    "        return lambda rt: np.full_like(np.asarray(rt, dtype=float), c)\n",
    "\n",
    "    def f(rt):\n",
    "        rt = np.asarray(rt, dtype=float)\n",
    "        return np.interp(rt, x, y, left=y[0], right=y[-1])\n",
    "    return f\n",
    "\n",
    "def align_runs_from_h5(h5_path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      aligned_df   : per-scan DataFrame with rt_correction and rt_aligned\n",
    "      drift_table  : per-bin drift table for all targets\n",
    "    \"\"\"\n",
    "    df = load_h5_build_df(h5_path)\n",
    "\n",
    "    # reference & targets\n",
    "    sample_order = df[\"sample_name\"].dropna().unique().tolist()\n",
    "    if len(sample_order) < 2:\n",
    "        raise ValueError(f\"Need ≥2 samples to align; found {len(sample_order)}: {sample_order}\")\n",
    "    ref_name = sample_order[0]\n",
    "    target_names = sample_order[1:]\n",
    "\n",
    "    df_ref = df[df[\"sample_name\"] == ref_name].copy()\n",
    "    if df_ref.empty:\n",
    "        raise ValueError(f\"No reference rows found for '{ref_name}'.\")\n",
    "    mz_ref   = df_ref[\"m/z\"].to_numpy()\n",
    "    rt_ref   = df_ref[\"retntion time\"].to_numpy()\n",
    "    cast_ref = df_ref[\"cast spectra\"].to_numpy(object)\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"rt_correction\"] = 0.0\n",
    "    df[\"rt_aligned\"] = df[\"retntion time\"].astype(float)\n",
    "\n",
    "    all_drifts = []  # collect per-target drift tables\n",
    "\n",
    "    if PLOT_DRIFT_CURVES:\n",
    "        plt.figure()\n",
    "        any_series = False\n",
    "\n",
    "    for tname in target_names:\n",
    "        dft = df[df[\"sample_name\"] == tname].copy()\n",
    "        if dft.empty:\n",
    "            print(f\"Warning: no rows for target '{tname}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        res_df, plot_df_valid = compute_drift_table_for_target(dft, mz_ref, rt_ref, cast_ref)\n",
    "\n",
    "        # add target name & collect drift table\n",
    "        res_df = res_df.copy()\n",
    "        res_df[\"target_name\"] = tname\n",
    "        all_drifts.append(res_df)\n",
    "\n",
    "        # optional: weighted avg summary\n",
    "        if not plot_df_valid.empty:\n",
    "            weights = plot_df_valid[\"n_valid_used\"].to_numpy()\n",
    "            vals    = plot_df_valid[\"avg_rt_drift\"].to_numpy()\n",
    "            wavg    = np.average(vals, weights=weights)\n",
    "            print(f\"{tname}: weighted overall avg drift = {wavg:.3f} min \"\n",
    "                  f\"(kept {plot_df_valid.shape[0]} bins with ≥1 valid match; TARGET_N={TARGET_N})\")\n",
    "        else:\n",
    "            print(f\"{tname}: no bins with ≥1 valid match.\")\n",
    "\n",
    "        if PLOT_DRIFT_CURVES and not plot_df_valid.empty:\n",
    "            plt.plot(plot_df_valid[\"bin_center_min\"], plot_df_valid[\"avg_rt_drift\"], marker=\"o\", label=tname)\n",
    "\n",
    "        # build & apply alignment\n",
    "        align_fn = build_alignment_function(plot_df_valid)\n",
    "        rt_vals = dft[\"retntion time\"].to_numpy(dtype=float)\n",
    "        corr = align_fn(rt_vals)\n",
    "        aligned = rt_vals - corr\n",
    "        df.loc[dft.index, \"rt_correction\"] = corr\n",
    "        df.loc[dft.index, \"rt_aligned\"] = aligned\n",
    "\n",
    "    # reference unchanged\n",
    "    df.loc[df[\"sample_name\"] == ref_name, \"rt_correction\"] = 0.0\n",
    "    df.loc[df[\"sample_name\"] == ref_name, \"rt_aligned\"] = df.loc[df[\"sample_name\"] == ref_name, \"retntion time\"].astype(float)\n",
    "\n",
    "    if PLOT_DRIFT_CURVES:\n",
    "        plt.axhline(0.0, linestyle=\"--\", color=\"gray\")\n",
    "        plt.axhline(5.0, linestyle=\"--\", alpha=0.6)\n",
    "        plt.axhline(-5.0, linestyle=\"--\", alpha=0.6)\n",
    "        plt.xlabel(\"Retention time (min, bin center)\")\n",
    "        plt.ylabel(\"Average RT drift vs ref (min)\")\n",
    "        # plt.legend(title=\"Target samples\", fontsize=9)\n",
    "        plt.grid(True, which=\"both\", linestyle=\":\", linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # combine drift tables\n",
    "    drift_table = pd.concat(all_drifts, ignore_index=True) if all_drifts else pd.DataFrame()\n",
    "\n",
    "    if PLOT_SANITY_AFTER:\n",
    "        plt.figure()\n",
    "        for name in df[\"sample_name\"].dropna().unique().tolist():\n",
    "            dfx = df[df[\"sample_name\"] == name]\n",
    "            tmp = dfx[[\"retntion time\", \"rt_correction\"]].copy()\n",
    "            tmp[\"bin\"] = (tmp[\"retntion time\"] // 2.0) * 2.0  # 2-min bins\n",
    "            grp = tmp.groupby(\"bin\", as_index=False)[\"rt_correction\"].median()\n",
    "            plt.plot(grp[\"bin\"], grp[\"rt_correction\"], marker=\".\", alpha=0.85, label=name)\n",
    "        plt.axhline(0.0, linestyle=\"--\", color=\"gray\")\n",
    "        plt.xlabel(\"Raw RT (min, 2-min bins)\")\n",
    "        plt.ylabel(\"Median applied correction (min)\")\n",
    "        # plt.legend(fontsize=8)\n",
    "        plt.grid(True, linestyle=\":\", linewidth=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return df, drift_table\n",
    "\n",
    "# =====================\n",
    "# Run\n",
    "# =====================\n",
    "if __name__ == \"__main__\":\n",
    "    aligned_df, drift_table = align_runs_from_h5(H5_PATH)\n",
    "\n",
    "    # Save aligned per-scan metadata (drop huge spectra)\n",
    "    if SAVE_ALIGNED_CSV:\n",
    "        os.makedirs(os.path.dirname(CSV_OUT_PATH), exist_ok=True)\n",
    "        aligned_df.drop(columns=[\"cast spectra\"], errors=\"ignore\").to_csv(CSV_OUT_PATH, index=False)\n",
    "        print(f\"Saved aligned metadata to: {CSV_OUT_PATH}\")\n",
    "\n",
    "    # Save per-bin drift table\n",
    "    if SAVE_DRIFTS_CSV:\n",
    "        os.makedirs(os.path.dirname(DRIFTS_CSV_PATH), exist_ok=True)\n",
    "        drift_table.to_csv(DRIFTS_CSV_PATH, index=False)\n",
    "        print(f\"Saved per-bin RT drifts to: {DRIFTS_CSV_PATH}\")\n",
    "\n",
    "    # Quick summary\n",
    "    for name in aligned_df[\"sample_name\"].dropna().unique().tolist():\n",
    "        dfx = aligned_df[aligned_df[\"sample_name\"] == name]\n",
    "        med_corr = float(np.nanmedian(dfx[\"rt_correction\"])) if len(dfx) else np.nan\n",
    "        print(f\"{name:30s} median correction: {med_corr: .3f} min\")\n",
    "\n",
    "    print(\"\\nColumns in aligned_df:\")\n",
    "    print(\"  sample_name, m/z, retntion time, rt_correction, rt_aligned, cast spectra\")\n",
    "    if not drift_table.empty:\n",
    "        print(\"\\nDrift table columns:\")\n",
    "        print(drift_table.columns.tolist())\n",
    "\n",
    "# ---- Make runs × bins drift matrix and save to CSV ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "SAVE_DRIFT_MATRIX_CSV = True\n",
    "DRIFT_MATRIX_CSV_PATH = r\"F:/casts/databank/rt_drifts_matrix1.csv\"\n",
    "\n",
    "if not drift_table.empty and SAVE_DRIFT_MATRIX_CSV:\n",
    "    dt = drift_table.copy()\n",
    "\n",
    "    # Use bin centers as columns (minutes). Round to 2 decimals for clean headers.\n",
    "    dt[\"bin_center_min\"] = dt[\"bin_center_min\"].astype(float).round(2)\n",
    "\n",
    "    # Pivot: rows=runs (target_name), cols=bins, values=avg drift\n",
    "    drift_matrix = (\n",
    "        dt.pivot_table(\n",
    "            index=\"target_name\",\n",
    "            columns=\"bin_center_min\",\n",
    "            values=\"avg_rt_drift\",\n",
    "            aggfunc=\"mean\"  # safe if duplicates ever appear\n",
    "        )\n",
    "        .sort_index(axis=1)  # sort bins left→right\n",
    "    )\n",
    "\n",
    "    # Optional: include the reference run as a zero row if you want it in the matrix\n",
    "    try:\n",
    "        ref_name = aligned_df[\"sample_name\"].dropna().unique().tolist()[0]\n",
    "        if ref_name not in drift_matrix.index:\n",
    "            # add zero drift across all bins for the reference\n",
    "            drift_matrix.loc[ref_name] = 0.0\n",
    "            drift_matrix = drift_matrix.sort_index()\n",
    "    except Exception:\n",
    "        pass  # skip if aligned_df is not available\n",
    "\n",
    "    # (Optional) prettier column labels like \"t00-10\", else keep numeric centers:\n",
    "    # dt2 = drift_table.copy()\n",
    "    # dt2[\"bin_label\"] = dt2[\"bin_start_min\"].astype(int).astype(str) + \"-\" + dt2[\"bin_end_min\"].astype(int).astype(str)\n",
    "    # drift_matrix = (dt2.pivot_table(index=\"target_name\", columns=\"bin_label\", values=\"avg_rt_drift\").sort_index(axis=1))\n",
    "\n",
    "    os.makedirs(os.path.dirname(DRIFT_MATRIX_CSV_PATH), exist_ok=True)\n",
    "    drift_matrix.to_csv(DRIFT_MATRIX_CSV_PATH, float_format=\"%.5f\")\n",
    "    print(f\"Saved drift matrix (runs × bins) to: {DRIFT_MATRIX_CSV_PATH}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc63be8",
   "metadata": {},
   "source": [
    "Using the drift table do the actual quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622d68c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: F:\\casts\\databank\\TreatmentD_aligned_bins_per_sample.csv\n"
     ]
    }
   ],
   "source": [
    "# Warning: this will wipe *everything* you defined in the current session!\n",
    "for var in list(globals().keys()):\n",
    "    if var[0] != \"_\":  # keep built-ins like __name__, __doc__, etc.\n",
    "        del globals()[var]\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------ helpers ------------------\n",
    "\n",
    "def _resolve_csv(path: str) -> str:\n",
    "    \"\"\"Return path (or path.csv) if exists; else raise.\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        return path\n",
    "    root, ext = os.path.splitext(path)\n",
    "    if not ext and os.path.exists(path + \".csv\"):\n",
    "        return path + \".csv\"\n",
    "    raise FileNotFoundError(f\"Drift file not found: {path}  (also tried {path+'.csv'})\")\n",
    "\n",
    "def _decode_bytes_arr(a):\n",
    "    \"\"\"Decode a 1D array of bytes/objects to str objects.\"\"\"\n",
    "    if isinstance(a, np.ndarray) and (a.dtype.kind in (\"S\", \"O\")):\n",
    "        out = []\n",
    "        for x in a:\n",
    "            if isinstance(x, (bytes, bytearray)):\n",
    "                try:\n",
    "                    out.append(x.decode(\"utf-8\"))\n",
    "                except Exception:\n",
    "                    out.append(str(x))\n",
    "            else:\n",
    "                out.append(str(x))\n",
    "        return np.array(out, dtype=object)\n",
    "    return a\n",
    "\n",
    "def _safe_metadata_from_npz_with_lut(z: np.lib.npyio.NpzFile, n_rows: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust metadata builder:\n",
    "      - keep 1D arrays of length n_rows\n",
    "      - broadcast 0D or length-1 arrays\n",
    "      - skip other shapes/lengths (e.g., ms2_* if mismatched)\n",
    "      - build sample_name from file_names_lookup[ms1_file_id] when available\n",
    "      - set retntion time from ms1_rt\n",
    "    \"\"\"\n",
    "    cols = {}\n",
    "    for k in z.files:\n",
    "        if k == \"ms1_matrix\":\n",
    "            continue\n",
    "        arr = z[k]\n",
    "        # Keep lookups for later mapping\n",
    "        if k in (\"file_names_lookup\", \"file_paths_lookup\"):\n",
    "            cols[k] = arr\n",
    "            continue\n",
    "\n",
    "        a = np.asarray(arr)\n",
    "        if a.ndim == 0:\n",
    "            cols[k] = np.repeat(a.item(), n_rows)\n",
    "        elif a.ndim == 1:\n",
    "            if a.shape[0] == n_rows:\n",
    "                cols[k] = a\n",
    "            elif a.shape[0] == 1:\n",
    "                cols[k] = np.repeat(a[0], n_rows)\n",
    "            else:\n",
    "                # skip mismatched lengths\n",
    "                pass\n",
    "        else:\n",
    "            # skip 2D+\n",
    "            pass\n",
    "\n",
    "    df = pd.DataFrame({k: cols[k] for k in cols if k not in (\"file_names_lookup\", \"file_paths_lookup\")})\n",
    "\n",
    "    # decode bytes in df columns\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == object or str(df[c].dtype).startswith(\"|S\"):\n",
    "            df[c] = pd.Series([x.decode(\"utf-8\") if isinstance(x, (bytes, bytearray)) else x for x in df[c]])\n",
    "\n",
    "    # sample_name via file_names_lookup[ms1_file_id] when possible\n",
    "    if \"ms1_file_id\" in df.columns and \"file_names_lookup\" in cols:\n",
    "        fid = pd.Series(df[\"ms1_file_id\"]).astype(int).to_numpy()\n",
    "        names_lut = _decode_bytes_arr(cols[\"file_names_lookup\"])\n",
    "        names_lut = np.asarray(names_lut, dtype=object)\n",
    "        fallback = np.array([f\"fid_{i}\" for i in fid], dtype=object)\n",
    "        ok = (fid >= 0) & (fid < names_lut.shape[0])\n",
    "        mapped = fallback.copy()\n",
    "        mapped[ok] = names_lut[fid[ok]]\n",
    "        df[\"sample_name\"] = mapped.astype(str)\n",
    "    else:\n",
    "        if \"file_name\" in df.columns:\n",
    "            df[\"sample_name\"] = df[\"file_name\"].astype(str)\n",
    "        elif \"raw_name\" in df.columns:\n",
    "            df[\"sample_name\"] = df[\"raw_name\"].astype(str)\n",
    "        elif \"run_name\" in df.columns:\n",
    "            df[\"sample_name\"] = df[\"run_name\"].astype(str)\n",
    "        elif \"ms1_file_id\" in df.columns:\n",
    "            df[\"sample_name\"] = (\"fid_\" + pd.Series(df[\"ms1_file_id\"]).astype(int).astype(str)).astype(str)\n",
    "        else:\n",
    "            df[\"sample_name\"] = \"UnknownRun\"\n",
    "\n",
    "    if \"group_name\" not in df.columns:\n",
    "        df[\"group_name\"] = \"Unknown\"\n",
    "\n",
    "    # retention time (legacy spelling)\n",
    "    if \"retntion time\" not in df.columns:\n",
    "        if \"ms1_rt\" in df.columns:\n",
    "            df[\"retntion time\"] = pd.Series(df[\"ms1_rt\"]).astype(float)\n",
    "        elif \"retention_time\" in df.columns:\n",
    "            df[\"retntion time\"] = pd.Series(df[\"retention_time\"]).astype(float)\n",
    "        elif \"rt\" in df.columns:\n",
    "            df[\"retntion time\"] = pd.Series(df[\"rt\"]).astype(float)\n",
    "        elif {\"rt_min\", \"rt_max\"}.issubset(df.columns):\n",
    "            df[\"retntion time\"] = (pd.Series(df[\"rt_min\"]).astype(float) + pd.Series(df[\"rt_max\"]).astype(float)) / 2.0\n",
    "        else:\n",
    "            raise KeyError(\"Couldn't infer 'retntion time' (looked for ms1_rt, retention_time, rt, rt_min/rt_max).\")\n",
    "\n",
    "    df[\"sample_name\"] = df[\"sample_name\"].astype(str)\n",
    "    df[\"group_name\"]  = df[\"group_name\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def _build_align_functions_from_drift(drift_path: str):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      1) Wide matrix CSV: index=runs, columns=bin centers (minutes)\n",
    "      2) Long table  CSV: target_name, bin_center_min, avg_rt_drift\n",
    "    All missing values are filled with 0.\n",
    "    Returns (fns, default_fn) where default_fn is the zero-curve.\n",
    "    \"\"\"\n",
    "    p = _resolve_csv(drift_path)\n",
    "\n",
    "    # Try wide matrix first\n",
    "    try:\n",
    "        wide = pd.read_csv(p, index_col=0)\n",
    "        # convert column names to numeric bin centers\n",
    "        bin_centers = []\n",
    "        ok = True\n",
    "        for c in wide.columns:\n",
    "            try:\n",
    "                bin_centers.append(float(c))\n",
    "            except Exception:\n",
    "                ok = False\n",
    "                break\n",
    "        if ok and len(bin_centers) > 0:\n",
    "            order = np.argsort(bin_centers)\n",
    "            cols_sorted = [wide.columns[i] for i in order]\n",
    "            wide = wide.loc[:, cols_sorted]\n",
    "            x_all = np.array([float(c) for c in cols_sorted], dtype=float)\n",
    "\n",
    "            # fill all missing with 0\n",
    "            wide = wide.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "            fns = {}\n",
    "            for run, row in wide.iterrows():\n",
    "                y = row.to_numpy(dtype=float)  # NaNs already 0\n",
    "                if x_all.size == 1:\n",
    "                    c = float(y[0])\n",
    "                    fns[str(run)] = (lambda c: (lambda rt: np.full_like(np.asarray(rt, float), c)))(c)\n",
    "                else:\n",
    "                    def make_f(xv, yv):\n",
    "                        def f(rt):\n",
    "                            rt = np.asarray(rt, float)\n",
    "                            return np.interp(rt, xv, yv, left=yv[0], right=yv[-1])\n",
    "                        return f\n",
    "                    fns[str(run)] = make_f(x_all, y)\n",
    "\n",
    "            default_fn = lambda rt: np.zeros_like(np.asarray(rt, float))\n",
    "            return fns, default_fn\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Fallback: long table\n",
    "    long = pd.read_csv(p)\n",
    "    # normalize headers\n",
    "    rename = {}\n",
    "    for need in (\"target_name\", \"bin_center_min\", \"avg_rt_drift\"):\n",
    "        if need not in long.columns:\n",
    "            for c in long.columns:\n",
    "                if c.lower() == need.lower():\n",
    "                    rename[c] = need\n",
    "    if rename:\n",
    "        long = long.rename(columns=rename)\n",
    "    for need in (\"target_name\", \"bin_center_min\", \"avg_rt_drift\"):\n",
    "        if need not in long.columns:\n",
    "            raise KeyError(f\"Drift file missing column '{need}'\")\n",
    "\n",
    "    # full grid of bin centers\n",
    "    all_bins = np.sort(long[\"bin_center_min\"].astype(float).unique())\n",
    "\n",
    "    fns = {}\n",
    "    for run, grp in long.groupby(\"target_name\"):\n",
    "        # initialize y as zeros (missing -> 0)\n",
    "        y = np.zeros_like(all_bins, dtype=float)\n",
    "        x_run = grp[\"bin_center_min\"].astype(float).to_numpy()\n",
    "        y_run = grp[\"avg_rt_drift\"].astype(float).to_numpy()\n",
    "        # map provided points\n",
    "        idx_map = {bx: i for i, bx in enumerate(all_bins)}\n",
    "        for xr, yr in zip(x_run, y_run):\n",
    "            i = idx_map.get(xr, None)\n",
    "            if i is not None and np.isfinite(yr):\n",
    "                y[i] = yr  # others remain 0\n",
    "\n",
    "        if all_bins.size == 1:\n",
    "            c = float(y[0])\n",
    "            fns[str(run)] = (lambda c: (lambda rt: np.full_like(np.asarray(rt, float), c)))(c)\n",
    "        else:\n",
    "            def make_f(xv, yv):\n",
    "                def f(rt):\n",
    "                    rt = np.asarray(rt, float)\n",
    "                    return np.interp(rt, xv, yv, left=yv[0], right=yv[-1])\n",
    "                return f\n",
    "            fns[str(run)] = make_f(all_bins, y)\n",
    "\n",
    "    default_fn = lambda rt: np.zeros_like(np.asarray(rt, float))\n",
    "    return fns, default_fn\n",
    "\n",
    "def _sum_rows_chunked(M, idxs, chunk_rows=1024, out_dtype=np.float32):\n",
    "    \"\"\"Memory-safe sum over selected rows.\"\"\"\n",
    "    if idxs.size == 0:\n",
    "        return np.zeros(M.shape[1], dtype=out_dtype)\n",
    "    acc = np.zeros(M.shape[1], dtype=np.float64)\n",
    "    for s in range(0, idxs.size, chunk_rows):\n",
    "        block = M[idxs[s:s+chunk_rows]]\n",
    "        acc += block.sum(axis=0, dtype=np.float64)\n",
    "    return acc.astype(out_dtype, copy=False)\n",
    "\n",
    "# ------------------ main (per-sample) ------------------\n",
    "\n",
    "def bin_ms1_npz_with_alignment_per_sample(\n",
    "    npz_path: str,\n",
    "    drift_path: str,\n",
    "    out_csv_path: str,\n",
    "    bin_width: float = 10.0,\n",
    "    overlap: float = 2.5,\n",
    "    num_bins: int = 8,\n",
    "    chunk_rows: int = 1024\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Align per-scan RT using per-run drift curves, then for **each sample_name**\n",
    "    sum MS1 spectra into 8 bins (10 min) with ±2.5 min overlap on aligned RT.\n",
    "    Missing drift values -> 0. Writes ONE CSV with 8 rows per sample.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(npz_path):\n",
    "        raise FileNotFoundError(npz_path)\n",
    "\n",
    "    z = np.load(npz_path, allow_pickle=True)\n",
    "    if \"ms1_matrix\" not in z:\n",
    "        raise KeyError(\"NPZ must contain 'ms1_matrix'\")\n",
    "    MS1 = z[\"ms1_matrix\"]       # shape: (N, L)\n",
    "    N, L = MS1.shape\n",
    "\n",
    "    # metadata with sample_name, group_name, retntion time\n",
    "    metadata = _safe_metadata_from_npz_with_lut(z, n_rows=N)\n",
    "\n",
    "    # build align functions; default is zero-curve\n",
    "    align_fns, default_fn = _build_align_functions_from_drift(drift_path)\n",
    "\n",
    "    # per-scan aligned RT\n",
    "    rt_raw = metadata[\"retntion time\"].to_numpy(dtype=float)\n",
    "    runs   = metadata[\"sample_name\"].astype(str).to_numpy()\n",
    "    groups = metadata[\"group_name\"].astype(str).to_numpy()\n",
    "\n",
    "    rt_corr = np.zeros_like(rt_raw, dtype=float)\n",
    "    for run in np.unique(runs):\n",
    "        f = align_fns.get(run, default_fn)  # if run missing -> zero drift\n",
    "        m = (runs == run)\n",
    "        if np.any(m):\n",
    "            rt_corr[m] = f(rt_raw[m])\n",
    "    rt_aligned = rt_raw - rt_corr\n",
    "\n",
    "    # fixed bins: [0, 80) stepped by 10, with ±2.5 overlap on aligned RT\n",
    "    starts  = np.arange(0.0, num_bins * bin_width, bin_width, dtype=float)\n",
    "    ends    = starts + bin_width\n",
    "    centers = 0.5 * (starts + ends)\n",
    "\n",
    "    # Precompute for clipping\n",
    "    rt_min = float(np.nanmin(rt_aligned)) if rt_aligned.size else 0.0\n",
    "    rt_max = float(np.nanmax(rt_aligned)) if rt_aligned.size else 0.0\n",
    "\n",
    "    cast_cols = [f\"cast_{i:05d}\" for i in range(L)]\n",
    "    rows = []\n",
    "\n",
    "    # ---- PER-SAMPLE LOOP ----\n",
    "    unique_runs = np.unique(runs)\n",
    "    for run in unique_runs:\n",
    "        idx_run = np.flatnonzero(runs == run)\n",
    "        if idx_run.size == 0:\n",
    "            continue\n",
    "\n",
    "        # group label for this run (assume constant within run)\n",
    "        grp_vals = np.unique(groups[idx_run])\n",
    "        group_label = grp_vals[0] if grp_vals.size > 0 else \"Unknown\"\n",
    "\n",
    "        rt_run = rt_aligned[idx_run]\n",
    "\n",
    "        for t0, t1, mid in zip(starts, ends, centers):\n",
    "            win_start = max(t0 - overlap, rt_min)\n",
    "            win_end   = min(t1 + overlap, rt_max)\n",
    "\n",
    "            # indices of this run that fall in the window\n",
    "            mask_local = (rt_run >= win_start) & (rt_run < win_end)\n",
    "            idxs = idx_run[mask_local]\n",
    "            n_scans = int(idxs.size)\n",
    "\n",
    "            if n_scans > 0:\n",
    "                vec = _sum_rows_chunked(MS1, idxs, chunk_rows=chunk_rows, out_dtype=np.float32)\n",
    "                rt_obs_min = float(rt_run[mask_local].min())\n",
    "                rt_obs_max = float(rt_run[mask_local].max())\n",
    "            else:\n",
    "                vec = np.zeros(L, dtype=np.float32)\n",
    "                rt_obs_min, rt_obs_max = np.nan, np.nan\n",
    "\n",
    "            # include sample_name so output is per-sample\n",
    "            rows.append([\n",
    "                run, group_label,\n",
    "                t0, t1, win_start, win_end, mid,\n",
    "                n_scans, rt_obs_min, rt_obs_max\n",
    "            ] + vec.tolist())\n",
    "\n",
    "    out_df = pd.DataFrame(\n",
    "        rows,\n",
    "        columns=[\n",
    "            \"sample_name\", \"group_name\",\n",
    "            \"rt_start_min\",\"rt_end_min\",\n",
    "            \"expanded_start_min\",\"expanded_end_min\",\n",
    "            \"rt_center_min\",\"n_scans\",\n",
    "            \"rt_aligned_min_obs\",\"rt_aligned_max_obs\"\n",
    "        ] + cast_cols\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(out_csv_path), exist_ok=True)\n",
    "    out_df.to_csv(out_csv_path, index=False)\n",
    "    return out_csv_path\n",
    "\n",
    "# ------------------ run ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    npz_path   = r\"F:\\casts\\databank\\TreatmentD.ms1.npz\"\n",
    "    drift_path = r\"F:\\casts\\databank\\rt_drifts_matrix\"  # auto-tries .csv\n",
    "    out_csv    = r\"F:\\casts\\databank\\TreatmentD_aligned_bins_per_sample.csv\"\n",
    "\n",
    "    wrote = bin_ms1_npz_with_alignment_per_sample(\n",
    "        npz_path=npz_path,\n",
    "        drift_path=drift_path,\n",
    "        out_csv_path=out_csv,\n",
    "        bin_width=10.0,\n",
    "        overlap=2.5,\n",
    "        num_bins=8,\n",
    "        chunk_rows=1024  # lower if you still see MemoryError\n",
    "    )\n",
    "    print(\"Saved:\", wrote)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
